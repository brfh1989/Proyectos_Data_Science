{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "\u00a1Hola!\n\nMi nombre es Marcos Torres y tengo el gusto de revisar tu c\u00f3digo el d\u00eda de hoy.\n\nCuando vea algo notable o alg\u00fan asunto en el notebook, te dejar\u00e9 un comentario o un hint. Se que encontraras la mejor respuesta para resolver todos los comentarios, de no ser as\u00ed, no te preocupes en futuras iteraciones dejar\u00e9 comentarios y pistas m\u00e1s espec\u00edficos.\n\nEncontrar\u00e1s comentarios en verde, amarillo o rojo como los siguientes:\n\n<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBuen trabajo. \u00a1Lo hiciste muy bien!\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nNota. Se puede mejorar.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nNecesitas corregirlo. Este bloque indica que se requiere una correci\u00f3n. El trabajo no se acepta si tiene estos bloques.\n</div>\n\nPuedes responder a mis comentarios usando estos bloques:\n\n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante.</b> <a class=\"tocSkip\"></a>\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "# Proyecto: Recomendaci\u00f3n de Planes de Megaline\n\nEn un esfuerzo por optimizar la experiencia de sus clientes y maximizar su rentabilidad, la compa\u00f1\u00eda m\u00f3vil **Megaline** busca desarrollar un modelo de machine learning capaz de analizar el comportamiento de sus usuarios y recomendar uno de sus nuevos planes tarifarios: **Smart** o **Ultra**. Este proyecto tiene como objetivo principal identificar patrones en los datos de uso de los clientes que ya se han cambiado a estos planes, permitiendo una clasificaci\u00f3n precisa de futuros usuarios seg\u00fan sus h\u00e1bitos.\n\n## Objetivos del Proyecto\n1. **Crear un modelo predictivo** que recomiende el plan tarifario m\u00e1s adecuado para un cliente, bas\u00e1ndose en su comportamiento de uso de llamadas, mensajes y datos de internet.\n2. **Garantizar una alta exactitud** en las recomendaciones, con un umbral m\u00ednimo de exactitud del 75%.\n3. **Comparar diferentes modelos y ajustar hiperpar\u00e1metros**, evaluando su calidad mediante m\u00e9tricas de desempe\u00f1o.\n\n## Preguntas que se Abordar\u00e1n\n1. \u00bfQu\u00e9 tan limpio y adecuado es el dataset para realizar un an\u00e1lisis predictivo?\n2. \u00bfC\u00f3mo se puede segmentar de manera efectiva el dataset en conjuntos de entrenamiento, validaci\u00f3n y prueba?\n3. \u00bfCu\u00e1les son los modelos m\u00e1s adecuados para esta tarea de clasificaci\u00f3n, y c\u00f3mo impacta el ajuste de hiperpar\u00e1metros en su desempe\u00f1o?\n4. \u00bfQu\u00e9 modelo logra la mayor exactitud en las predicciones y cumple con el umbral establecido?\n5. \u00bfEl modelo final es robusto al punto de superar una prueba de cordura, asegurando su capacidad de generalizaci\u00f3n?\n\nCon este proyecto, **Megaline** espera no solo mejorar la satisfacci\u00f3n del cliente al ofrecerle planes que se ajusten a sus necesidades, sino tambi\u00e9n optimizar sus operaciones al migrar a m\u00e1s clientes hacia sus nuevos planes tarifarios.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "Primero se importa toda la librer\u00eda, que se va a utilizar durante el proceso. Adem\u00e1s de incluir los datos que se van a manipular."}, {"cell_type": "code", "execution_count": 25, "metadata": {"trusted": false}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>calls</th>\n      <th>minutes</th>\n      <th>messages</th>\n      <th>mb_used</th>\n      <th>is_ultra</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.0</td>\n      <td>311.90</td>\n      <td>83.0</td>\n      <td>19915.42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85.0</td>\n      <td>516.75</td>\n      <td>56.0</td>\n      <td>22696.96</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>77.0</td>\n      <td>467.66</td>\n      <td>86.0</td>\n      <td>21060.45</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106.0</td>\n      <td>745.53</td>\n      <td>81.0</td>\n      <td>8437.39</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>66.0</td>\n      <td>418.74</td>\n      <td>1.0</td>\n      <td>14502.75</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   calls  minutes  messages   mb_used  is_ultra\n0   40.0   311.90      83.0  19915.42         0\n1   85.0   516.75      56.0  22696.96         0\n2   77.0   467.66      86.0  21060.45         0\n3  106.0   745.53      81.0   8437.39         1\n4   66.0   418.74       1.0  14502.75         0"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "# Importaci\u00f3n de librer\u00edas necesarias\nimport pandas as pd  # Para manipulaci\u00f3n de datos\nimport numpy as np # Para operaciones matem\u00e1ticas\nfrom sklearn.model_selection import train_test_split  # Para dividir los datos\nfrom sklearn.tree import DecisionTreeClassifier  # Modelo de \u00c1rbol de Decisi\u00f3n\nfrom sklearn.ensemble import RandomForestClassifier  # Modelo de Bosque Aleatorio\nfrom sklearn.linear_model import LogisticRegression  # Modelo de Regresi\u00f3n Log\u00edstica\nfrom sklearn.metrics import accuracy_score, classification_report  # M\u00e9tricas de evaluaci\u00f3n\n\n# Cargar los datos\ndata = pd.read_csv('/datasets/users_behavior.csv')  # Ruta al archivo CSV\n    \n# Visualizar las primeras filas\ndata.head()\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBien, usaste una celda independiente para importar las librer\u00edas y otra para leer los datos.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "Ahora se va a proceder con una inspecci\u00f3n r\u00e1pida de la tabla para luego pasar al entrenamiento"}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Informaci\u00f3n general del dataset:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3214 entries, 0 to 3213\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   calls     3214 non-null   float64\n 1   minutes   3214 non-null   float64\n 2   messages  3214 non-null   float64\n 3   mb_used   3214 non-null   float64\n 4   is_ultra  3214 non-null   int64  \ndtypes: float64(4), int64(1)\nmemory usage: 125.7 KB\n\nN\u00famero de filas duplicadas: 0\n\nN\u00famero de valores nulos por columna:\ncalls       0\nminutes     0\nmessages    0\nmb_used     0\nis_ultra    0\ndtype: int64\n\nEstad\u00edsticas b\u00e1sicas del dataset:\n             calls      minutes     messages       mb_used     is_ultra\ncount  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\nmean     63.038892   438.208787    38.281269  17207.673836     0.306472\nstd      33.236368   234.569872    36.148326   7570.968246     0.461100\nmin       0.000000     0.000000     0.000000      0.000000     0.000000\n25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n75%      82.000000   571.927500    57.000000  21424.700000     1.000000\nmax     244.000000  1632.060000   224.000000  49745.730000     1.000000\n"}], "source": "# Inspecci\u00f3n b\u00e1sica de la estructura del dataset\nprint(\"Informaci\u00f3n general del dataset:\")\ndata.info()\n\n# Verificar si hay valores duplicados\nduplicates = data.duplicated().sum()\nprint(f\"\\nN\u00famero de filas duplicadas: {duplicates}\")\n\n# Verificar si hay valores nulos\nnulls = data.isnull().sum()\nprint(\"\\nN\u00famero de valores nulos por columna:\")\nprint(nulls)\n\n# Inspeccionar las estad\u00edsticas b\u00e1sicas para detectar valores at\u00edpicos o inconsistencias\nprint(\"\\nEstad\u00edsticas b\u00e1sicas del dataset:\")\nprint(data.describe())\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBuen uso de los m\u00e9todos de pandas para explorar los datos.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "El dataset contiene 3214 observaciones y 5 columnas sin valores nulos ni duplicados, indicando que est\u00e1 limpio y listo para el an\u00e1lisis. Las variables (calls, minutes, messages, mb_used) muestran una amplia dispersi\u00f3n, con algunos usuarios que no utilizaron ciertos servicios y otros con valores extremos (hasta 244 llamadas, 1632 minutos o casi 50 GB de internet). Adem\u00e1s, solo el 30.6% de los usuarios est\u00e1n en el plan Ultra (is_ultra), lo que refleja un desbalance de clases importante para el modelo.\n\nAhora que ya tenemos la seguridad que los datos est\u00e1n listos para ser procesados se va a proseguir con la siguiente parte. "}, {"cell_type": "markdown", "metadata": {}, "source": "Se dividen los datos en tres partes: entrenamiento (60%), validaci\u00f3n (20%) y prueba (20%) para asegurar que el modelo aprenda bien y pueda hacer buenas predicciones con datos nuevos. Usamos los datos de entrenamiento para que el modelo aprenda, los de validaci\u00f3n para probar diferentes configuraciones y elegir la mejor opci\u00f3n, y los de prueba para ver c\u00f3mo funcionar\u00e1 en situaciones completamente nuevas. Este m\u00e9todo es com\u00fan porque equilibra bien los datos entre aprender, ajustar y evaluar, y usamos un n\u00famero fijo (random_state) para que los resultados sean consistentes al repetir el proceso. Adem\u00e1s, dividimos los datos al azar para que el an\u00e1lisis sea justo."}, {"cell_type": "code", "execution_count": 7, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Conjunto de entrenamiento: (1928, 5)\nConjunto de validaci\u00f3n: (643, 5)\nConjunto de prueba: (643, 5)\n"}], "source": "# Segmentaci\u00f3n del dataset en conjuntos de entrenamiento, validaci\u00f3n y prueba\ndf_train, df_temp = train_test_split(data, test_size=0.4, random_state=54321)  # 60% entrenamiento\ndf_valid, df_test = train_test_split(df_temp, test_size=0.5, random_state=54321)  # 20% validaci\u00f3n y 20% prueba\n\n# Verificar las dimensiones de los conjuntos\nprint(f\"Conjunto de entrenamiento: {df_train.shape}\")\nprint(f\"Conjunto de validaci\u00f3n: {df_valid.shape}\")\nprint(f\"Conjunto de prueba: {df_test.shape}\")\n\n# Separar caracter\u00edsticas y variable objetivo del conjunto de entrenamiento\nfeatures_train = df_train.drop('is_ultra', axis=1)\ntarget_train = df_train['is_ultra']\n\n# Separar caracter\u00edsticas y variable objetivo del conjunto de validaci\u00f3n\nfeatures_valid = df_valid.drop('is_ultra', axis=1)\ntarget_valid = df_valid['is_ultra']"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSe dividieron adecuadamente los datos en entrenamiento y prueba y la variable objetivo se filtro correctamente.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "Con esto comprobamos que los conjuntos est\u00e1n divididos de manera adecuada. \n\nAhora se prosigue con el entrenamiento de los modelos. Se entrenar\u00e1n tres modelos: un \u00e1rbol de decisi\u00f3n, un bosque aleatorio y una regresi\u00f3n log\u00edstica, utilizando las caracter\u00edsticas (calls, minutes, messages, mb_used) como variables predictoras y is_ultra como variable objetivo. A continuaci\u00f3n, se evaluar\u00e1 el desempe\u00f1o inicial de cada modelo en el conjunto de validaci\u00f3n mediante el c\u00e1lculo de la exactitud. Posteriormente, se proceder\u00e1 a optimizar los hiperpar\u00e1metros clave de cada modelo, con el objetivo de mejorar su rendimiento."}, {"cell_type": "markdown", "metadata": {}, "source": "**Metodolog\u00eda y justificaci\u00f3n de hiperpar\u00e1metros de \u00e1rbol de decisi\u00f3n**\n\nLos valores seleccionados para los hiperpar\u00e1metros permiten realizar un barrido exhaustivo y equilibrado, optimizando el rendimiento del \u00e1rbol de decisi\u00f3n. El rango de max_depth entre 1 y 20 incluye tanto \u00e1rboles simples, que evitan el sobreajuste, como \u00e1rboles m\u00e1s complejos para capturar relaciones detalladas en los datos. Para min_samples_split, se consideraron valores entre 2 y 10, garantizando que las divisiones de los nodos solo se realicen con un m\u00ednimo razonable de observaciones, lo que previene particiones innecesarias. Asimismo, min_samples_leaf se prob\u00f3 entre 1 y 10 para evitar que los nodos hoja sean demasiado peque\u00f1os, mejorando la estabilidad de las predicciones. Finalmente, los criterios gini y entropy fueron incluidos por ser las m\u00e9tricas est\u00e1ndar en la evaluaci\u00f3n de la calidad de las divisiones. Esta configuraci\u00f3n permite explorar desde modelos simples hasta configuraciones m\u00e1s complejas, asegurando una optimizaci\u00f3n adecuada del modelo sin sobrecargar el proceso computacional."}, {"cell_type": "code", "execution_count": 12, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Mejor exactitud: 0.7932\nMejores hiperpar\u00e1metros:\n{'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8, 'criterion': 'entropy'}\n"}], "source": "# Valores de hiperpar\u00e1metros a explorar\nmax_depths = range (1,21)\nmin_samples_splits = range (2,11)\nmin_samples_leaves = range (1,11)\ncriterions = ['gini', 'entropy']\n\n# Variables para almacenar el mejor modelo y resultados\nbest_accuracy = 0\nbest_params = None\n\n# Barrido de hiperpar\u00e1metros\nfor depth in max_depths:\n    for split in min_samples_splits:\n        for leaf in min_samples_leaves:\n            for crit in criterions:\n                # Crear y entrenar el modelo\n                model = DecisionTreeClassifier(\n                    max_depth=depth,\n                    min_samples_split=split,\n                    min_samples_leaf=leaf,\n                    criterion=crit,\n                    random_state=54321\n                )\n                model.fit(features_train, target_train)\n                predictions = model.predict(features_valid)\n                accuracy = accuracy_score(target_valid, predictions)\n                \n                # Actualizar el mejor modelo\n                if accuracy > best_accuracy:\n                    best_accuracy = accuracy\n                    best_params = {\n                        'max_depth': depth,\n                        'min_samples_split': split,\n                        'min_samples_leaf': leaf,\n                        'criterion': crit\n                    }\n\n# Resultados del mejor modelo\nprint(f\"Mejor exactitud: {best_accuracy:.4f}\")\nprint(\"Mejores hiperpar\u00e1metros:\")\nprint(best_params)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\n\u00a1Muy bien! La exploraci\u00f3n de los hiperpar\u00e1metros se realiz\u00f3 correctamente.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "El modelo de \u00e1rbol de decisi\u00f3n alcanz\u00f3 una exactitud \u00f3ptima del 79.32% tras ajustar los hiperpar\u00e1metros. Con una profundidad m\u00e1xima de 7, el \u00e1rbol logra un equilibrio adecuado entre simplicidad y capacidad para capturar patrones. El m\u00ednimo de muestras para dividir fue establecido en 2, permitiendo realizar divisiones siempre que sea posible. Adem\u00e1s, el m\u00ednimo de muestras en una hoja se fij\u00f3 en 8, asegurando que cada nodo final tenga suficientes datos para generar predicciones consistentes y robustas. Por \u00faltimo, el criterio de divisi\u00f3n elegido, entropy, utiliza la ganancia de informaci\u00f3n como m\u00e9trica, lo que parece ajustarse mejor a las caracter\u00edsticas del dataset.\n\nCon los valores establecidos se procede a evaluar con el conjunto de prueba y determinar la efectividad del modelo."}, {"cell_type": "code", "execution_count": 16, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Exactitud en el conjunto de prueba: 0.8180\n"}], "source": "\n# Entrenar el modelo con los mejores hiperpar\u00e1metros\nfinal_tree_model = DecisionTreeClassifier(\n    max_depth=7,\n    min_samples_split=2,\n    min_samples_leaf=8,\n    criterion='entropy',\n    random_state=54321\n)\nfinal_tree_model.fit(features_train, target_train)\n\n# Evaluar en el conjunto de prueba\ntest_predictions = final_tree_model.predict(df_test.drop('is_ultra', axis=1))\ntest_accuracy = accuracy_score(df_test['is_ultra'], test_predictions)\n\n# Mostrar resultados\nprint(f\"Exactitud en el conjunto de prueba: {test_accuracy:.4f}\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSe entren\u00f3 correctamente el modelo de \u00e1rbol de decisi\u00f3n con los mejores hiperpar\u00e1metros que se obtuvieron.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "**Conclusi\u00f3n Parcial: \u00c1rbol de Decisi\u00f3n**\n\nEl modelo de \u00e1rbol de decisi\u00f3n optimizado alcanz\u00f3 una **exactitud del 81.80%** al ser evaluado en el conjunto de prueba, superando el umbral esperado de 75%. Este resultado indica que el modelo tiene una buena capacidad para generalizar a datos nuevos, logrando un equilibrio adecuado entre simplicidad y precisi\u00f3n gracias a la configuraci\u00f3n de hiperpar\u00e1metros como una profundidad m\u00e1xima de 7 y un m\u00ednimo de 8 muestras en las hojas. Estos ajustes permitieron evitar tanto el sobreajuste como el subajuste, consolid\u00e1ndose como una soluci\u00f3n efectiva para clasificar los planes **Smart** y **Ultra**.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBuenas conclusiones parciales.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "**Metodolog\u00eda y Justificaci\u00f3n de Hiperpar\u00e1metros para el Bosque Aleatorio**\n\nEl modelo de bosque aleatorio, al combinar m\u00faltiples \u00e1rboles de decisi\u00f3n entrenados de forma independiente, requiere la optimizaci\u00f3n de varios hiperpar\u00e1metros para lograr un equilibrio entre precisi\u00f3n y eficiencia. El n\u00famero de \u00e1rboles (`n_estimators`) se probar\u00e1 con valores de 50, 100 y 150, buscando identificar c\u00f3mo la estabilidad del modelo mejora con m\u00e1s estimadores, sin incrementar innecesariamente el tiempo de entrenamiento. La profundidad m\u00e1xima de los \u00e1rboles (`max_depth`) se evaluar\u00e1 en 5, 10, 15 y sin l\u00edmite (`None`), permitiendo explorar configuraciones que capturen patrones importantes sin caer en el sobreajuste. El m\u00ednimo de muestras necesarias para dividir un nodo (`min_samples_split`) se probar\u00e1 con valores de 2, 5 y 10, representando configuraciones flexibles y conservadoras para las divisiones. Por otro lado, el m\u00ednimo de muestras en una hoja (`min_samples_leaf`) se ajustar\u00e1 con valores de 1, 2 y 4, lo que garantiza nodos m\u00e1s robustos sin comprometer la flexibilidad del modelo. Finalmente, se considerar\u00e1n ambos criterios de divisi\u00f3n, `gini` y `entropy`, para evaluar cu\u00e1l optimiza mejor las divisiones en funci\u00f3n de las caracter\u00edsticas del dataset. Este barrido, aunque menos exhaustivo, abarca un rango amplio y estrat\u00e9gico que permite encontrar configuraciones \u00f3ptimas en menor tiempo, mejorando la generalizaci\u00f3n y precisi\u00f3n del modelo.\n\n"}, {"cell_type": "code", "execution_count": 21, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Mejor exactitud: 0.7978\nMejores hiperpar\u00e1metros:\n{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini'}\n"}], "source": "# Valores de hiperpar\u00e1metros ajustados para un barrido m\u00e1s r\u00e1pido\nn_estimators = [50, 100, 150]  \nmax_depths = [5, 10, 15, None]  \nmin_samples_splits = [2, 5, 10]  \nmin_samples_leaves = [1, 2, 4]  \ncriterions = ['gini', 'entropy'] \n\n# Variables para almacenar el mejor modelo y resultados\nbest_accuracy = 0\nbest_params = None\n\n# Barrido optimizado de hiperpar\u00e1metros\nfor n_tree in n_estimators:\n    for depth in max_depths:\n        for split in min_samples_splits:\n            for leaf in min_samples_leaves:\n                for crit in criterions:\n                    # Crear y entrenar el modelo\n                    model = RandomForestClassifier(\n                        n_estimators=n_tree,\n                        max_depth=depth,\n                        min_samples_split=split,\n                        min_samples_leaf=leaf,\n                        criterion=crit,\n                        random_state=54321\n                    )\n                    model.fit(features_train, target_train)\n                    predictions = model.predict(features_valid)\n                    accuracy = accuracy_score(target_valid, predictions)\n                    \n                    # Actualizar el mejor modelo\n                    if accuracy > best_accuracy:\n                        best_accuracy = accuracy\n                        best_params = {\n                            'n_estimators': n_tree,\n                            'max_depth': depth,\n                            'min_samples_split': split,\n                            'min_samples_leaf': leaf,\n                            'criterion': crit\n                        }\n\n# Resultados del mejor modelo\nprint(f\"Mejor exactitud: {best_accuracy:.4f}\")\nprint(\"Mejores hiperpar\u00e1metros:\")\nprint(best_params)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBuen uso de los ciclos for anidados para encontrar los mejores hiperpar\u00e1metros. Ayuda a visualizar mejor lo que se est\u00e1 evaluando.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nEste proceso para evaluar distintos hiperpar\u00e1metros es muy bueno, pero para realizar evaluaci\u00f3n de distintos hiperpar\u00e1metros ya existen librer\u00edas que exploran los hiperpar\u00e1metros como GridSearchCV.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "**Metodolog\u00eda y Justificaci\u00f3n de Hiperpar\u00e1metros para el Bosque Aleatorio**\n\nEl modelo de bosque aleatorio alcanz\u00f3 una **exactitud del 79.78%** tras optimizar sus hiperpar\u00e1metros. Se seleccionaron los valores \u00f3ptimos: `n_estimators = 100`, `max_depth = 10`, `min_samples_split = 2`, `min_samples_leaf = 1` y `criterion = 'gini'`. Uno de los principales retos durante el an\u00e1lisis fue el tiempo requerido para ejecutar un barrido exhaustivo, lo que llev\u00f3 a la decisi\u00f3n de reducir el rango de valores a un conjunto estrat\u00e9gico, equilibrando la profundidad del an\u00e1lisis y la eficiencia computacional. Este enfoque permiti\u00f3 identificar una configuraci\u00f3n robusta en un tiempo razonable, asegurando un buen equilibrio entre precisi\u00f3n y estabilidad del modelo.\n\nAhora se hace un an\u00e1lisis con los datos del conjunto de prueba.\n"}, {"cell_type": "code", "execution_count": 22, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Exactitud en el conjunto de prueba: 0.8336\n"}], "source": "# Entrenar el modelo final con los mejores hiperpar\u00e1metros\nfinal_forest_model = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=10,\n    min_samples_split=2,\n    min_samples_leaf=1,\n    criterion='gini',\n    random_state=54321\n)\nfinal_forest_model.fit(features_train, target_train)\n\n# Evaluar en el conjunto de prueba\ntest_predictions = final_forest_model.predict(df_test.drop('is_ultra', axis=1))\ntest_accuracy = accuracy_score(df_test['is_ultra'], test_predictions)\n\n# Mostrar resultados\nprint(f\"Exactitud en el conjunto de prueba: {test_accuracy:.4f}\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBien, la exactitud del mejor modelo de bosques aleatorios es muy buena, superaste la solicitada de 0.75\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "**Conclusi\u00f3n Parcial: Bosque Aleatorio**\n\nEl modelo de bosque aleatorio optimizado alcanz\u00f3 una **exactitud del 83.36%** en el conjunto de prueba, superando tanto el umbral esperado de 75% como el desempe\u00f1o del modelo de \u00e1rbol de decisi\u00f3n. Este resultado demuestra que la estrategia de combinar m\u00faltiples \u00e1rboles de decisi\u00f3n permiti\u00f3 mejorar significativamente la capacidad de generalizaci\u00f3n del modelo, al reducir el riesgo de sobreajuste y capturar patrones m\u00e1s complejos en los datos. Los hiperpar\u00e1metros \u00f3ptimos, como un n\u00famero moderado de \u00e1rboles (`n_estimators = 100`), una profundidad m\u00e1xima controlada (`max_depth = 10`), y el criterio `gini`, contribuyeron a equilibrar precisi\u00f3n y eficiencia. La decisi\u00f3n de limitar el barrido de hiperpar\u00e1metros debido al tiempo requerido para el an\u00e1lisis result\u00f3 ser acertada, permitiendo encontrar una configuraci\u00f3n robusta en un tiempo razonable.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "**Metodolog\u00eda y Justificaci\u00f3n de Hiperpar\u00e1metros para la Regresi\u00f3n Log\u00edstica**\n\nEl modelo de **regresi\u00f3n log\u00edstica** se optimiz\u00f3 mediante un barrido de hiperpar\u00e1metros enfocado en los m\u00e1s relevantes para su desempe\u00f1o. Se seleccion\u00f3 el solver `liblinear` debido a su compatibilidad con datasets peque\u00f1os y su capacidad para manejar problemas de clasificaci\u00f3n binaria de manera eficiente. El hiperpar\u00e1metro `C`, que controla la fuerza de la regularizaci\u00f3n, se prob\u00f3 con valores `[0.01, 0.1, 1, 10, 100]`. Este rango permiti\u00f3 explorar desde una regularizaci\u00f3n fuerte (con valores bajos) hasta una casi inexistente (con valores altos), buscando el mejor equilibrio entre ajuste y generalizaci\u00f3n. Adem\u00e1s, el n\u00famero m\u00e1ximo de iteraciones (`max_iter`) se fij\u00f3 en 1000 para garantizar la convergencia del modelo, y se utiliz\u00f3 un `random_state` de 54321 para asegurar la reproducibilidad de los resultados. Este enfoque permiti\u00f3 identificar la configuraci\u00f3n \u00f3ptima para maximizar la exactitud en el conjunto de validaci\u00f3n.\n"}, {"cell_type": "code", "execution_count": 24, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Mejor exactitud: 0.6781\nMejores hiperpar\u00e1metros:\n{'solver': 'liblinear', 'C': 0.1}\n"}], "source": "# Valores de hiperpar\u00e1metros a explorar\nsolvers = ['liblinear']\nregularizations = [0.01, 0.1, 1, 10, 100]\n\n# Variables para almacenar el mejor modelo y resultados\nbest_accuracy = 0\nbest_params = None\n\n# Barrido de hiperpar\u00e1metros\nfor solver in solvers:\n    for c in regularizations:\n        # Crear y entrenar el modelo\n        model = LogisticRegression(\n            solver=solver,\n            C=c,\n            max_iter=1000,\n            random_state=54321\n        )\n        model.fit(features_train, target_train)\n        predictions = model.predict(features_valid)\n        accuracy = accuracy_score(target_valid, predictions)\n        \n        # Actualizar el mejor modelo\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_params = {\n                'solver': solver,\n                'C': c\n            }\n\n# Resultados del mejor modelo\nprint(f\"Mejor exactitud: {best_accuracy:.4f}\")\nprint(\"Mejores hiperpar\u00e1metros:\")\nprint(best_params)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBuen trabajo, la regresi\u00f3n log\u00edstica se evalu\u00f3 correctamente, aunque no obtuvo un resultado en exactitud tan sobresaliente, pero esto es por la naturaleza del modelo.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "**Conclusi\u00f3n Parcial: Regresi\u00f3n Log\u00edstica**\n\nEl modelo de regresi\u00f3n log\u00edstica alcanz\u00f3 una **exactitud del 67.81%** en el conjunto de validaci\u00f3n, siendo inferior al desempe\u00f1o observado en los modelos de \u00e1rbol de decisi\u00f3n y bosque aleatorio. Esta diferencia puede atribuirse a las limitaciones de la regresi\u00f3n log\u00edstica, ya que asume relaciones lineales entre las caracter\u00edsticas y la variable objetivo, lo que la hace menos efectiva en datasets con patrones m\u00e1s complejos o no lineales. Aunque podr\u00edan explorarse mejoras como el escalado de las caracter\u00edsticas, la creaci\u00f3n de nuevas variables o el ajuste de par\u00e1metros adicionales, estas opciones no se consideraron debido a restricciones dentro del sprint impartido. \n"}, {"cell_type": "markdown", "metadata": {}, "source": "**Prueba de Cordura**\n\nLa prueba de cordura se realiz\u00f3 para verificar que el modelo optimizado funciona significativamente mejor que un modelo aleatorio, garantizando que los resultados no son producto del azar. Para ello, se cre\u00f3 un modelo aleatorio que asigna etiquetas de manera aleatoria a los datos del conjunto de prueba, respetando la proporci\u00f3n de las clases presentes en el dataset. Posteriormente, se compar\u00f3 la exactitud del modelo aleatorio con la del modelo optimizado.\n\nEl modelo con el mejor desempe\u00f1o fue el **bosque aleatorio**, que alcanz\u00f3 una **exactitud del 83.36%** en el conjunto de prueba. Este modelo utiliz\u00f3 los siguientes hiperpar\u00e1metros \u00f3ptimos:\n- **N\u00famero de \u00e1rboles (`n_estimators`)**: 100.\n- **Profundidad m\u00e1xima (`max_depth`)**: 10.\n- **M\u00ednimo de muestras para dividir (`min_samples_split`)**: 2.\n- **M\u00ednimo de muestras en una hoja (`min_samples_leaf`)**: 1.\n- **Criterio de divisi\u00f3n (`criterion`)**: `gini`.\n\nAl comparar este modelo con el desempe\u00f1o de un modelo aleatorio, se espera que el bosque aleatorio supere ampliamente al modelo aleatorio, demostrando que los resultados son significativos y no aleatorios.\n"}, {"cell_type": "code", "execution_count": 26, "metadata": {"trusted": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Exactitud del modelo aleatorio: 0.6470\nExactitud del mejor modelo (Bosque Aleatorio): 0.8336\nEl modelo optimizado supera la prueba de cordura.\n"}], "source": "# Generar predicciones aleatorias basadas en la proporci\u00f3n de clases en el conjunto de prueba\nrandom_predictions = np.random.choice(\n    df_test['is_ultra'].unique(),  # Clases posibles (0 y 1)\n    size=len(df_test),             # N\u00famero de predicciones a generar\n    p=df_test['is_ultra'].value_counts(normalize=True).values  # Probabilidades basadas en la distribuci\u00f3n de clases\n)\n\n# Calcular la exactitud del modelo aleatorio\nrandom_accuracy = accuracy_score(df_test['is_ultra'], random_predictions)\n\n# Mostrar resultados\nprint(f\"Exactitud del modelo aleatorio: {random_accuracy:.4f}\")\nprint(f\"Exactitud del mejor modelo (Bosque Aleatorio): 0.8336\")  # Cambiar si el mejor modelo cambia\n\n# Verificar si el modelo optimizado supera la prueba de cordura\nif random_accuracy < 0.8336:  # Sustituir por la exactitud del mejor modelo si es diferente\n    print(\"El modelo optimizado supera la prueba de cordura.\")\nelse:\n    print(\"El modelo optimizado no supera la prueba de cordura.\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBuen trabajo, la prueba de cordura se realiz\u00f3 correctamente.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "**Prueba de Cordura: Resultados**\n\nEl modelo aleatorio alcanz\u00f3 una **exactitud del 64.70%**, consistente con la distribuci\u00f3n de clases en el conjunto de prueba. En comparaci\u00f3n, el modelo optimizado de **bosque aleatorio** logr\u00f3 una **exactitud del 83.36%**, superando significativamente al modelo aleatorio. Este resultado confirma que el modelo optimizado tiene un desempe\u00f1o superior y que no clasifica los datos de forma aleatoria, sino que identifica patrones relevantes que mejoran la predicci\u00f3n de los planes **Smart** y **Ultra**. Por lo tanto, el modelo optimizado supera satisfactoriamente la prueba de cordura.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "**Conclusi\u00f3n General del Proyecto**\n\nEl proyecto permiti\u00f3 desarrollar y evaluar diferentes modelos de machine learning para clasificar los planes **Smart** y **Ultra** de la compa\u00f1\u00eda Megaline, logrando resultados satisfactorios. Se probaron tres modelos principales: \u00e1rbol de decisi\u00f3n, bosque aleatorio y regresi\u00f3n log\u00edstica. El **bosque aleatorio** optimizado demostr\u00f3 ser el modelo m\u00e1s efectivo, alcanzando una **exactitud del 83.36%** en el conjunto de prueba, superando ampliamente el umbral esperado del 75% y la exactitud del modelo aleatorio (64.70%). Este resultado valida su capacidad para capturar patrones significativos en los datos, mientras mantiene un equilibrio entre precisi\u00f3n y eficiencia computacional. Aunque la regresi\u00f3n log\u00edstica tuvo un desempe\u00f1o limitado (67.81%), fue \u00fatil como referencia para entender las limitaciones de modelos lineales en problemas m\u00e1s complejos. En conclusi\u00f3n, el bosque aleatorio no solo demostr\u00f3 ser robusto y fiable, sino que super\u00f3 la prueba de cordura, consolid\u00e1ndose como la mejor opci\u00f3n para recomendar los planes tarifarios bas\u00e1ndose en los datos de comportamiento de los usuarios.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nBuenas conclusiones, se resume lo realizado a lo largo del proyecto.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\n\u00a1Hola! \n\nTe felicito por tu proyecto, est\u00e1 muy bien realizado y completo, exploraste varios modelos y en cada modelo usaste una muy buena t\u00e9cnica de exploraci\u00f3n de sus hiperpar\u00e1metros. Obtuviste un buen nivel de exactitud de 83%, superando el umbral de 75% y de la prueba de cordura. Bien hecho, puedo aprobar tu proyecto, \u00e9xito en los siguientes sprints.\n    \nSaludos, Marcos.\n</div>"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "outputs": [], "source": ""}], "metadata": {"ExecuteTimeLog": [{"duration": 1024, "start_time": "2025-01-28T00:40:59.563Z"}, {"duration": 15, "start_time": "2025-01-28T00:41:21.493Z"}, {"duration": 21, "start_time": "2025-01-28T00:42:43.694Z"}, {"duration": 22, "start_time": "2025-01-28T01:13:06.740Z"}, {"duration": 8, "start_time": "2025-01-28T01:47:45.811Z"}, {"duration": 19, "start_time": "2025-01-28T02:08:43.397Z"}, {"duration": 8, "start_time": "2025-01-28T02:11:24.731Z"}, {"duration": 471, "start_time": "2025-01-28T02:11:29.435Z"}, {"duration": 1373, "start_time": "2025-01-28T02:17:18.298Z"}, {"duration": 1710, "start_time": "2025-01-28T02:18:47.886Z"}, {"duration": 5106, "start_time": "2025-01-28T02:52:29.653Z"}, {"duration": 25029, "start_time": "2025-01-28T02:56:58.104Z"}, {"duration": 15, "start_time": "2025-01-28T03:17:18.777Z"}, {"duration": 12, "start_time": "2025-01-28T03:17:52.010Z"}, {"duration": 13, "start_time": "2025-01-28T03:18:15.224Z"}, {"duration": 13, "start_time": "2025-01-28T03:19:04.920Z"}, {"duration": 67326, "start_time": "2025-01-28T03:39:43.252Z"}, {"duration": 0, "start_time": "2025-01-28T03:54:20.076Z"}, {"duration": 9297, "start_time": "2025-01-28T03:54:49.967Z"}, {"duration": 58189, "start_time": "2025-01-28T03:57:50.495Z"}, {"duration": 263, "start_time": "2025-01-28T04:05:29.646Z"}, {"duration": 838, "start_time": "2025-01-28T04:16:11.811Z"}, {"duration": 25, "start_time": "2025-01-28T04:21:52.118Z"}, {"duration": 13, "start_time": "2025-01-28T04:35:48.008Z"}, {"duration": 15, "start_time": "2025-01-28T04:36:00.254Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}