{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Hola Bruno! <a class=\"tocSkip\"></a>\n\nMi nombre es Oscar Flores y tengo el gusto de revisar tu proyecto. Si tienes alg\u00fan comentario que quieras agregar en tus respuestas te puedes referir a mi como Oscar, no hay problema que me trates de t\u00fa.\n\nSi veo un error en la primera revisi\u00f3n solamente lo se\u00f1alar\u00e9 y dejar\u00e9 que t\u00fa encuentres de qu\u00e9 se trata y c\u00f3mo arreglarlo. Debo prepararte para que te desempe\u00f1es como especialista en Data, en un trabajo real, el responsable a cargo tuyo har\u00e1 lo mismo. Si a\u00fan tienes dificultades para resolver esta tarea, te dar\u00e9 indicaciones m\u00e1s precisas en una siguiente iteraci\u00f3n.\n\nTe dejar\u00e9 mis comentarios m\u00e1s abajo - **por favor, no los muevas, modifiques o borres**\n\nComenzar\u00e9 mis comentarios con un resumen de los puntos que est\u00e1n bien, aquellos que debes corregir y aquellos que puedes mejorar. Luego deber\u00e1s revisar todo el notebook para leer mis comentarios, los cuales estar\u00e1n en rect\u00e1ngulos de color verde, amarillo o rojo como siguen:\n\n<div class=\"alert alert-block alert-success\">\n<b>Comentario de Reviewer</b> <a class=\"tocSkip\"></a>\n    \nMuy bien! Toda la respuesta fue lograda satisfactoriamente.\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Comentario de Reviewer</b> <a class=\"tocSkip\"></a>\n\nExisten detalles a mejorar. Existen recomendaciones.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n\n<b>Comentario de Reviewer</b> <a class=\"tocSkip\"></a>\n\nSe necesitan correcciones en el bloque. El trabajo no puede ser aceptado con comentarios en rojo sin solucionar.\n</div>\n\nCualquier comentario que quieras agregar entre iteraciones de revisi\u00f3n lo puedes hacer de la siguiente manera:\n\n<div class=\"alert alert-block alert-info\">\n<b>Respuesta estudiante.</b> <a class=\"tocSkip\"></a>\n</div>\n\nMucho \u00e9xito en el proyecto!"}, {"cell_type": "markdown", "metadata": {}, "source": "## Resumen de la revisi\u00f3n 1 <a class=\"tocSkip\"></a>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nFelicitaciones Bruno! Has aprobado el proyecto en la primera iteraci\u00f3n. Tu trabajo est\u00e1 muy bueno, completo y ordenado. La calidad de los an\u00e1lisis que realizaste est\u00e1n a un excelente nivel, lo que uno espera de un especialista de datos. Vas muy bien orientado en tu aprendizaje y se ve que lo aplicas correctamente. Continua as\u00ed, tendr\u00e1s mucho \u00e9xito.\n    \nSaludos!    \n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "----"}, {"cell_type": "markdown", "metadata": {}, "source": "El servicio de venta de autos usados Rusty Bargain est\u00e1 desarrollando una aplicaci\u00f3n para atraer nuevos clientes. Gracias a esa app, puedes averiguar r\u00e1pidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones t\u00e9cnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\nA Rusty Bargain le interesa:\n- la calidad de la predicci\u00f3n;\n- la velocidad de la predicci\u00f3n;\n- el tiempo requerido para el entrenamiento"}, {"cell_type": "markdown", "metadata": {}, "source": "# Proyecto: Predicci\u00f3n de Valor de Mercado para Rusty Bargain\n\n## Introducci\u00f3n\n\nEl servicio de venta de coches de segunda mano, Rusty Bargain, est\u00e1 desarrollando una aplicaci\u00f3n para facilitar a los usuarios la estimaci\u00f3n del valor de mercado de sus veh\u00edculos. El objetivo principal de este proyecto es construir un modelo de Machine Learning que pueda predecir el precio de un coche (`Price`) bas\u00e1ndose en sus caracter\u00edsticas hist\u00f3ricas y t\u00e9cnicas.\n\nPara Rusty Bargain, no solo es importante la **calidad de la predicci\u00f3n**, sino tambi\u00e9n la **velocidad** con la que el modelo puede generar estas predicciones y el **tiempo** que requiere su entrenamiento. Por lo tanto, evaluaremos los modelos utilizando la m\u00e9trica **RECM (Ra\u00edz del Error Cuadr\u00e1tico Medio)** y mediremos los tiempos de entrenamiento y predicci\u00f3n.\n\nEn este cuaderno, realizaremos los siguientes pasos:\n* Cargaremos y exploraremos el conjunto de datos proporcionado.\n* Realizaremos la limpieza y preprocesamiento necesarios para preparar los datos para el modelado.\n* Entrenaremos y evaluaremos varios modelos de regresi\u00f3n, incluyendo Regresi\u00f3n Lineal (como prueba de cordura), modelos basados en \u00e1rboles (\u00c1rbol de Decisi\u00f3n, Bosque Aleatorio) y modelos de potenciaci\u00f3n del gradiente (LightGBM y opcionalmente XGBoost/CatBoost).\n* Ajustaremos los hiperpar\u00e1metros de los modelos m\u00e1s prometedores.\n* Analizaremos y compararemos el rendimiento de los modelos en funci\u00f3n de la calidad (RECM), la velocidad de predicci\u00f3n y el tiempo de entrenamiento.\n* Finalmente, concluiremos cu\u00e1l modelo se ajusta mejor a las necesidades de Rusty Bargain."}, {"cell_type": "markdown", "metadata": {}, "source": "##  Importaci\u00f3n de Librer\u00edas\n\nImportamos las librer\u00edas necesarias para el an\u00e1lisis de datos, preprocesamiento, modelado y evaluaci\u00f3n."}, {"cell_type": "code", "execution_count": 21, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Librer\u00edas importadas exitosamente.\n"}], "source": "# --- An\u00e1lisis y Manipulaci\u00f3n de Datos ---\nimport pandas as pd\nimport numpy as np\nimport time\n\n# --- Visualizaci\u00f3n ---\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# --- Preprocesamiento ---\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import Pipeline\n\n# --- Modelos ---\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\n\n# --- M\u00e9tricas de Evaluaci\u00f3n ---\nfrom sklearn.metrics import mean_squared_error\n\nprint(\"Librer\u00edas importadas exitosamente.\")"}, {"cell_type": "markdown", "metadata": {}, "source": "## Preparaci\u00f3n de datos: Carga y Exploraci\u00f3n Inicial de Datos\n\nComenzamos cargando el conjunto de datos desde el archivo CSV proporcionado. Luego, realizaremos una exploraci\u00f3n inicial para entender su estructura, el tipo de informaci\u00f3n que contiene cada columna, la presencia de valores nulos y estad\u00edsticas descriptivas b\u00e1sicas. Esto nos dar\u00e1 una primera visi\u00f3n de los datos y nos ayudar\u00e1 a identificar los pasos necesarios para la limpieza y preprocesamiento.\n\n**Acciones:**\n1. Cargar el dataset usando pandas.\n2. Mostrar las primeras filas para visualizar los datos.\n3. Obtener informaci\u00f3n general (tipos de datos, valores no nulos) con `.info()`.\n4. Calcular estad\u00edsticas descriptivas para las columnas num\u00e9ricas con `.describe()`.\n5. Verificar las dimensiones del dataset (n\u00famero de filas y columnas) con `.shape`.\n6. Comprobar si existen filas duplicadas completas."}, {"cell_type": "code", "execution_count": 2, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Primeras 5 filas del dataset:\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateCrawled</th>\n      <th>Price</th>\n      <th>VehicleType</th>\n      <th>RegistrationYear</th>\n      <th>Gearbox</th>\n      <th>Power</th>\n      <th>Model</th>\n      <th>Mileage</th>\n      <th>RegistrationMonth</th>\n      <th>FuelType</th>\n      <th>Brand</th>\n      <th>NotRepaired</th>\n      <th>DateCreated</th>\n      <th>NumberOfPictures</th>\n      <th>PostalCode</th>\n      <th>LastSeen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24/03/2016 11:52</td>\n      <td>480</td>\n      <td>NaN</td>\n      <td>1993</td>\n      <td>manual</td>\n      <td>0</td>\n      <td>golf</td>\n      <td>150000</td>\n      <td>0</td>\n      <td>petrol</td>\n      <td>volkswagen</td>\n      <td>NaN</td>\n      <td>24/03/2016 00:00</td>\n      <td>0</td>\n      <td>70435</td>\n      <td>07/04/2016 03:16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24/03/2016 10:58</td>\n      <td>18300</td>\n      <td>coupe</td>\n      <td>2011</td>\n      <td>manual</td>\n      <td>190</td>\n      <td>NaN</td>\n      <td>125000</td>\n      <td>5</td>\n      <td>gasoline</td>\n      <td>audi</td>\n      <td>yes</td>\n      <td>24/03/2016 00:00</td>\n      <td>0</td>\n      <td>66954</td>\n      <td>07/04/2016 01:46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14/03/2016 12:52</td>\n      <td>9800</td>\n      <td>suv</td>\n      <td>2004</td>\n      <td>auto</td>\n      <td>163</td>\n      <td>grand</td>\n      <td>125000</td>\n      <td>8</td>\n      <td>gasoline</td>\n      <td>jeep</td>\n      <td>NaN</td>\n      <td>14/03/2016 00:00</td>\n      <td>0</td>\n      <td>90480</td>\n      <td>05/04/2016 12:47</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17/03/2016 16:54</td>\n      <td>1500</td>\n      <td>small</td>\n      <td>2001</td>\n      <td>manual</td>\n      <td>75</td>\n      <td>golf</td>\n      <td>150000</td>\n      <td>6</td>\n      <td>petrol</td>\n      <td>volkswagen</td>\n      <td>no</td>\n      <td>17/03/2016 00:00</td>\n      <td>0</td>\n      <td>91074</td>\n      <td>17/03/2016 17:40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31/03/2016 17:25</td>\n      <td>3600</td>\n      <td>small</td>\n      <td>2008</td>\n      <td>manual</td>\n      <td>69</td>\n      <td>fabia</td>\n      <td>90000</td>\n      <td>7</td>\n      <td>gasoline</td>\n      <td>skoda</td>\n      <td>no</td>\n      <td>31/03/2016 00:00</td>\n      <td>0</td>\n      <td>60437</td>\n      <td>06/04/2016 10:17</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n0  24/03/2016 11:52    480         NaN              1993  manual      0   \n1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n2  14/03/2016 12:52   9800         suv              2004    auto    163   \n3  17/03/2016 16:54   1500       small              2001  manual     75   \n4  31/03/2016 17:25   3600       small              2008  manual     69   \n\n   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n0   golf   150000                  0    petrol  volkswagen         NaN   \n1    NaN   125000                  5  gasoline        audi         yes   \n2  grand   125000                  8  gasoline        jeep         NaN   \n3   golf   150000                  6    petrol  volkswagen          no   \n4  fabia    90000                  7  gasoline       skoda          no   \n\n        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  "}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "\nInformaci\u00f3n general del dataset:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 354369 entries, 0 to 354368\nData columns (total 16 columns):\n #   Column             Non-Null Count   Dtype \n---  ------             --------------   ----- \n 0   DateCrawled        354369 non-null  object\n 1   Price              354369 non-null  int64 \n 2   VehicleType        316879 non-null  object\n 3   RegistrationYear   354369 non-null  int64 \n 4   Gearbox            334536 non-null  object\n 5   Power              354369 non-null  int64 \n 6   Model              334664 non-null  object\n 7   Mileage            354369 non-null  int64 \n 8   RegistrationMonth  354369 non-null  int64 \n 9   FuelType           321474 non-null  object\n 10  Brand              354369 non-null  object\n 11  NotRepaired        283215 non-null  object\n 12  DateCreated        354369 non-null  object\n 13  NumberOfPictures   354369 non-null  int64 \n 14  PostalCode         354369 non-null  int64 \n 15  LastSeen           354369 non-null  object\ndtypes: int64(7), object(9)\nmemory usage: 43.3+ MB\n\nEstad\u00edsticas descriptivas (columnas num\u00e9ricas):\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>RegistrationYear</th>\n      <th>Power</th>\n      <th>Mileage</th>\n      <th>RegistrationMonth</th>\n      <th>NumberOfPictures</th>\n      <th>PostalCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>354369.000000</td>\n      <td>354369.000000</td>\n      <td>354369.000000</td>\n      <td>354369.000000</td>\n      <td>354369.000000</td>\n      <td>354369.0</td>\n      <td>354369.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4416.656776</td>\n      <td>2004.234448</td>\n      <td>110.094337</td>\n      <td>128211.172535</td>\n      <td>5.714645</td>\n      <td>0.0</td>\n      <td>50508.689087</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4514.158514</td>\n      <td>90.227958</td>\n      <td>189.850405</td>\n      <td>37905.341530</td>\n      <td>3.726421</td>\n      <td>0.0</td>\n      <td>25783.096248</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1000.000000</td>\n      <td>0.000000</td>\n      <td>5000.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1067.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1050.000000</td>\n      <td>1999.000000</td>\n      <td>69.000000</td>\n      <td>125000.000000</td>\n      <td>3.000000</td>\n      <td>0.0</td>\n      <td>30165.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2700.000000</td>\n      <td>2003.000000</td>\n      <td>105.000000</td>\n      <td>150000.000000</td>\n      <td>6.000000</td>\n      <td>0.0</td>\n      <td>49413.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6400.000000</td>\n      <td>2008.000000</td>\n      <td>143.000000</td>\n      <td>150000.000000</td>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>71083.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20000.000000</td>\n      <td>9999.000000</td>\n      <td>20000.000000</td>\n      <td>150000.000000</td>\n      <td>12.000000</td>\n      <td>0.0</td>\n      <td>99998.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "               Price  RegistrationYear          Power        Mileage  \\\ncount  354369.000000     354369.000000  354369.000000  354369.000000   \nmean     4416.656776       2004.234448     110.094337  128211.172535   \nstd      4514.158514         90.227958     189.850405   37905.341530   \nmin         0.000000       1000.000000       0.000000    5000.000000   \n25%      1050.000000       1999.000000      69.000000  125000.000000   \n50%      2700.000000       2003.000000     105.000000  150000.000000   \n75%      6400.000000       2008.000000     143.000000  150000.000000   \nmax     20000.000000       9999.000000   20000.000000  150000.000000   \n\n       RegistrationMonth  NumberOfPictures     PostalCode  \ncount      354369.000000          354369.0  354369.000000  \nmean            5.714645               0.0   50508.689087  \nstd             3.726421               0.0   25783.096248  \nmin             0.000000               0.0    1067.000000  \n25%             3.000000               0.0   30165.000000  \n50%             6.000000               0.0   49413.000000  \n75%             9.000000               0.0   71083.000000  \nmax            12.000000               0.0   99998.000000  "}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "\nDimensiones del dataset (filas, columnas):\n(354369, 16)\n\nN\u00famero de valores duplicados completos:\nSe encontraron 262 filas duplicadas.\n"}], "source": "# --- Carga de Datos ---\nfile_path = '/datasets/car_data.csv'\n\ndf = pd.read_csv(file_path)\n\n# --- Exploraci\u00f3n Inicial ---\nprint(\"Primeras 5 filas del dataset:\")\ndisplay(df.head())\n\nprint(\"\\nInformaci\u00f3n general del dataset:\")\ndf.info()\n\nprint(\"\\nEstad\u00edsticas descriptivas (columnas num\u00e9ricas):\")\ndisplay(df.describe())\n\nprint(\"\\nDimensiones del dataset (filas, columnas):\")\nprint(df.shape)\n\nprint(\"\\nN\u00famero de valores duplicados completos:\")\nprint(f\"Se encontraron {df.duplicated().sum()} filas duplicadas.\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\n\nBien, correcto\n\n\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "### `display(df.head())`\n\nLa visualizaci\u00f3n de las primeras filas confirma los nombres de las columnas y nos da una idea del tipo de datos que contienen. Inmediatamente se observa la presencia de valores nulos (`NaN`) en columnas importantes como `VehicleType`, `Gearbox`, `Model`, `FuelType` y `NotRepaired`. Tambi\u00e9n notamos que las columnas de fechas (`DateCrawled`, `DateCreated`, `LastSeen`) est\u00e1n almacenadas como texto (`object`), y que `RegistrationMonth` tiene un valor de 0 en la primera fila, lo cual es inusual para un mes.\n\n### `df.info()`\n\nEsta salida revela que el dataset tiene 354,369 entradas y 16 columnas. Confirma la presencia significativa de valores nulos en `VehicleType` (faltan ~37k), `Gearbox` (~20k), `Model` (~20k), `FuelType` (~33k) y `NotRepaired` (la columna con m\u00e1s nulos, faltan ~71k). Identifica 7 columnas de tipo num\u00e9rico (`int64`) y 9 de tipo texto (`object`), incluyendo las fechas y varias caracter\u00edsticas categ\u00f3ricas que requerir\u00e1n procesamiento. La memoria utilizada es de aproximadamente 43.3 MB.\n\n### `display(df.describe())`\n\nLas estad\u00edsticas descriptivas de las columnas num\u00e9ricas muestran varios puntos cr\u00edticos: `Price` tiene un m\u00ednimo de 0, lo cual no es realista. `RegistrationYear` presenta valores extremos imposibles (m\u00ednimo 1000, m\u00e1ximo 9999) que deben ser corregidos. `Power` tambi\u00e9n tiene valores an\u00f3malos (m\u00ednimo 0, m\u00e1ximo 20000). `Mileage` parece tener un l\u00edmite superior, ya que el percentil 75 y el m\u00e1ximo coinciden en 150,000 km. `RegistrationMonth` incluye el valor 0, que no corresponde a un mes v\u00e1lido. Por \u00faltimo, `NumberOfPictures` parece contener \u00fanicamente ceros, lo que la har\u00eda in\u00fatil para el modelo.\n\n### `print(df.shape)`\n\nEste comando confirma las dimensiones del DataFrame: 354,369 filas y 16 columnas. Esto coincide con la informaci\u00f3n de `df.info()` y nos da una idea clara del volumen de datos con el que estamos trabajando.\n\n### `print(f\"Se encontraron {df.duplicated().sum()} filas duplicadas.\")`\n\nSe detectaron 262 filas completamente duplicadas en el conjunto de datos. Estas filas id\u00e9nticas generalmente no aportan informaci\u00f3n adicional y pueden sesgar el entrenamiento, por lo que usualmente se eliminan durante la fase de limpieza."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\n\nMe parece muy bien tus comentarios de cada l\u00ednea de exploraci\u00f3n de la data, lo hace muy estructurado. \n\n\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "##  Limpieza Inicial: Duplicados y Columnas Irrelevantes\n\nBas\u00e1ndonos en la exploraci\u00f3n inicial, procederemos con los siguientes pasos de limpieza:\n\n1.  **Eliminar Filas Duplicadas:** Encontramos 262 filas que son copias exactas de otras. Estas no aportan informaci\u00f3n nueva y pueden introducir sesgos leves, por lo que las eliminaremos.\n2.  **Eliminar Columnas No Relevantes o Problem\u00e1ticas:**\n    * `NumberOfPictures`: Esta columna contiene \u00fanicamente el valor 0, por lo que no tiene varianza y no aportar\u00e1 poder predictivo al modelo.\n    * `DateCrawled`, `DateCreated`, `LastSeen`: Estas fechas se refieren a cu\u00e1ndo se recopil\u00f3 o actualiz\u00f3 el anuncio en la base de datos, no a caracter\u00edsticas intr\u00ednsecas del veh\u00edculo que determinen su valor de mercado actual. Por lo tanto, no se espera que sean predictores directos del precio y las eliminaremos para simplificar el modelo.\n    * `PostalCode`: Aunque la ubicaci\u00f3n puede influir en el precio, el c\u00f3digo postal es una variable categ\u00f3rica con much\u00edsimos valores \u00fanicos (alta cardinalidad). Codificarla adecuadamente requerir\u00eda t\u00e9cnicas m\u00e1s complejas (como target encoding o agrupar por regiones) que complican la comparaci\u00f3n inicial de modelos. Usarla como n\u00famero no tiene sentido. Por simplicidad, la eliminaremos en esta etapa.\n\nConservaremos `RegistrationYear` y `RegistrationMonth`, ya que reflejan directamente la antig\u00fcedad del veh\u00edculo, un factor clave en su precio. Sin embargo, recordamos que ambas columnas tienen valores an\u00f3malos que abordaremos m\u00e1s adelante.\n\n**Acciones:**\n1. Eliminar filas duplicadas.\n2. Eliminar las columnas `DateCrawled`, `DateCreated`, `LastSeen`, `PostalCode`, `NumberOfPictures`.\n3. Verificar las nuevas dimensiones del DataFrame."}, {"cell_type": "code", "execution_count": 3, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Se eliminaron 262 filas duplicadas.\nSe eliminaron las columnas: DateCrawled, DateCreated, LastSeen, PostalCode, NumberOfPictures\n\nNuevas dimensiones del dataset (filas, columnas):\n(354107, 11)\n\nInformaci\u00f3n general tras limpieza inicial:\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 354107 entries, 0 to 354368\nData columns (total 11 columns):\n #   Column             Non-Null Count   Dtype \n---  ------             --------------   ----- \n 0   Price              354107 non-null  int64 \n 1   VehicleType        316623 non-null  object\n 2   RegistrationYear   354107 non-null  int64 \n 3   Gearbox            334277 non-null  object\n 4   Power              354107 non-null  int64 \n 5   Model              334406 non-null  object\n 6   Mileage            354107 non-null  int64 \n 7   RegistrationMonth  354107 non-null  int64 \n 8   FuelType           321218 non-null  object\n 9   Brand              354107 non-null  object\n 10  NotRepaired        282962 non-null  object\ndtypes: int64(5), object(6)\nmemory usage: 32.4+ MB\n"}], "source": "# --- Eliminaci\u00f3n de Duplicados ---\nrows_before_dedup = df.shape[0]\ndf.drop_duplicates(inplace=True)\nrows_after_dedup = df.shape[0]\nprint(f\"Se eliminaron {rows_before_dedup - rows_after_dedup} filas duplicadas.\")\n\n# --- Eliminaci\u00f3n de Columnas ---\ncols_to_drop = ['DateCrawled', 'DateCreated', 'LastSeen', 'PostalCode', 'NumberOfPictures']\ndf.drop(columns=cols_to_drop, inplace=True)\nprint(f\"Se eliminaron las columnas: {', '.join(cols_to_drop)}\")\n\n# --- Verificaci\u00f3n Post-Limpieza Inicial ---\nprint(\"\\nNuevas dimensiones del dataset (filas, columnas):\")\nprint(df.shape)\n\nprint(\"\\nInformaci\u00f3n general tras limpieza inicial:\")\ndf.info()"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\n\nBien, correcta la eliminaci\u00f3n de los duplicados, si bien es posible tener la misma data para la venta de dos autos diferentes, dado que esta data incluye `DateCrawled`, se hace muy improbable que sean autos diferentes y, por lo tanto, es data repetida.\n\nAdicionalmente, est\u00e1 bien remover las columnas no informativas.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Tratamiento de Valores An\u00f3malos\n\nEn la exploraci\u00f3n inicial (`.describe()`), identificamos valores inveros\u00edmiles en varias columnas num\u00e9ricas clave: `Price`, `RegistrationYear` y `Power`, adem\u00e1s de un valor inv\u00e1lido (0) en `RegistrationMonth`. Estos valores pueden distorsionar el an\u00e1lisis y el rendimiento del modelo, por lo que procederemos a corregirlos o eliminarlos.\n\n**Estrategia:**\n\n* **`Price`**: El precio m\u00ednimo de 0\u20ac no es realista para un coche. Estableceremos un umbral m\u00ednimo razonable (ej. 100\u20ac) y eliminaremos los registros por debajo de este valor, asumiendo que son errores o entradas no v\u00e1lidas.\n* **`RegistrationYear`**: Los a\u00f1os 1000 y 9999 son claramente incorrectos. Considerando que los datos se recopilaron alrededor de 2016, definiremos un rango de a\u00f1os de matriculaci\u00f3n plausible, por ejemplo, entre 1950 y 2016 (inclusive). Los coches registrados fuera de este rango ser\u00e1n eliminados. Un coche no puede registrarse en el futuro respecto a la fecha de creaci\u00f3n del anuncio.\n* **`Power`**: Una potencia (CV) de 0 es imposible para un veh\u00edculo funcional. Tambi\u00e9n hay valores extremadamente altos (hasta 20000 CV) que son inveros\u00edmiles. Definiremos un rango de potencia razonable, por ejemplo, entre 10 CV y 1000 CV. Los registros fuera de este rango ser\u00e1n eliminados.\n* **`RegistrationMonth`**: El valor 0 no es un mes v\u00e1lido (deber\u00eda ser 1-12). En lugar de eliminar estas filas, lo cual podr\u00eda descartar datos por lo dem\u00e1s v\u00e1lidos, imputaremos estos valores. Una estrategia com\u00fan es reemplazar el valor inv\u00e1lido (0) por el mes m\u00e1s frecuente (la moda) entre los meses v\u00e1lidos (1-12).\n\n**Acciones:**\n1. Filtrar el DataFrame para mantener solo las filas con `Price` >= 100.\n2. Filtrar el DataFrame para mantener solo las filas con `RegistrationYear` entre 1950 y 2016.\n3. Filtrar el DataFrame para mantener solo las filas con `Power` entre 10 y 1000.\n4. Calcular la moda de `RegistrationMonth` (excluyendo el 0) y reemplazar los 0 con este valor.\n5. Verificar las estad\u00edsticas descriptivas (`.describe()`) nuevamente para confirmar la correcci\u00f3n de los rangos."}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tama\u00f1o del dataset antes de filtrar anomal\u00edas: (354107, 11)\nFiltrado Price < 100: Se eliminaron 13311 filas.\nFiltrado RegistrationYear fuera de [1950, 2016]: Se eliminaron 13831 filas.\nFiltrado Power fuera de [10, 1000]: Se eliminaron 32009 filas.\nTama\u00f1o del dataset despu\u00e9s de filtrar anomal\u00edas: (294956, 11)\n\nLa moda de RegistrationMonth (1-12) es: 3\nN\u00famero de filas con RegistrationMonth = 0: 17644\nSe reemplazaron los valores 0 de RegistrationMonth con 3.\n\nEstad\u00edsticas descriptivas tras corregir anomal\u00edas:\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>RegistrationYear</th>\n      <th>Power</th>\n      <th>Mileage</th>\n      <th>RegistrationMonth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>294956.000000</td>\n      <td>294956.000000</td>\n      <td>294956.000000</td>\n      <td>294956.000000</td>\n      <td>294956.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4873.878962</td>\n      <td>2002.841037</td>\n      <td>120.873622</td>\n      <td>128313.646781</td>\n      <td>6.178535</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4611.666600</td>\n      <td>6.488454</td>\n      <td>54.681220</td>\n      <td>36702.210956</td>\n      <td>3.343335</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100.000000</td>\n      <td>1950.000000</td>\n      <td>10.000000</td>\n      <td>5000.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1350.000000</td>\n      <td>1999.000000</td>\n      <td>76.000000</td>\n      <td>125000.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3200.000000</td>\n      <td>2003.000000</td>\n      <td>111.000000</td>\n      <td>150000.000000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6999.000000</td>\n      <td>2007.000000</td>\n      <td>150.000000</td>\n      <td>150000.000000</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20000.000000</td>\n      <td>2016.000000</td>\n      <td>1000.000000</td>\n      <td>150000.000000</td>\n      <td>12.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "               Price  RegistrationYear          Power        Mileage  \\\ncount  294956.000000     294956.000000  294956.000000  294956.000000   \nmean     4873.878962       2002.841037     120.873622  128313.646781   \nstd      4611.666600          6.488454      54.681220   36702.210956   \nmin       100.000000       1950.000000      10.000000    5000.000000   \n25%      1350.000000       1999.000000      76.000000  125000.000000   \n50%      3200.000000       2003.000000     111.000000  150000.000000   \n75%      6999.000000       2007.000000     150.000000  150000.000000   \nmax     20000.000000       2016.000000    1000.000000  150000.000000   \n\n       RegistrationMonth  \ncount      294956.000000  \nmean            6.178535  \nstd             3.343335  \nmin             1.000000  \n25%             3.000000  \n50%             6.000000  \n75%             9.000000  \nmax            12.000000  "}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "\nInformaci\u00f3n general tras corregir anomal\u00edas:\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 294956 entries, 1 to 354368\nData columns (total 11 columns):\n #   Column             Non-Null Count   Dtype \n---  ------             --------------   ----- \n 0   Price              294956 non-null  int64 \n 1   VehicleType        284135 non-null  object\n 2   RegistrationYear   294956 non-null  int64 \n 3   Gearbox            289697 non-null  object\n 4   Power              294956 non-null  int64 \n 5   Model              284025 non-null  object\n 6   Mileage            294956 non-null  int64 \n 7   RegistrationMonth  294956 non-null  int64 \n 8   FuelType           279630 non-null  object\n 9   Brand              294956 non-null  object\n 10  NotRepaired        252492 non-null  object\ndtypes: int64(5), object(6)\nmemory usage: 27.0+ MB\n"}], "source": "# --- Filtrado de Valores An\u00f3malos ---\nprint(f\"Tama\u00f1o del dataset antes de filtrar anomal\u00edas: {df.shape}\")\n\n# Filtrar Price\nrows_before = df.shape[0]\nprice_min_threshold = 100\ndf = df[df['Price'] >= price_min_threshold]\nrows_after = df.shape[0]\nprint(f\"Filtrado Price < {price_min_threshold}: Se eliminaron {rows_before - rows_after} filas.\")\n\n# Filtrar RegistrationYear\nrows_before = df.shape[0]\nyear_min_threshold = 1950\nyear_max_threshold = 2016 # Basado en la fecha de crawling/creaci\u00f3n\ndf = df[(df['RegistrationYear'] >= year_min_threshold) & (df['RegistrationYear'] <= year_max_threshold)]\nrows_after = df.shape[0]\nprint(f\"Filtrado RegistrationYear fuera de [{year_min_threshold}, {year_max_threshold}]: Se eliminaron {rows_before - rows_after} filas.\")\n\n# Filtrar Power\nrows_before = df.shape[0]\npower_min_threshold = 10\npower_max_threshold = 1000\ndf = df[(df['Power'] >= power_min_threshold) & (df['Power'] <= power_max_threshold)]\nrows_after = df.shape[0]\nprint(f\"Filtrado Power fuera de [{power_min_threshold}, {power_max_threshold}]: Se eliminaron {rows_before - rows_after} filas.\")\n\nprint(f\"Tama\u00f1o del dataset despu\u00e9s de filtrar anomal\u00edas: {df.shape}\")\n\n# --- Correcci\u00f3n de RegistrationMonth ---\n# Calcular la moda de los meses v\u00e1lidos (1-12)\nvalid_months = df[df['RegistrationMonth'].between(1, 12)]['RegistrationMonth']\nif not valid_months.empty:\n    month_mode = valid_months.mode()[0]\n    print(f\"\\nLa moda de RegistrationMonth (1-12) es: {month_mode}\")\n\n    # Contar cu\u00e1ntos meses son 0 antes de reemplazar\n    count_month_zero = df[df['RegistrationMonth'] == 0].shape[0]\n    print(f\"N\u00famero de filas con RegistrationMonth = 0: {count_month_zero}\")\n\n    # Reemplazar 0 con la moda\n    df['RegistrationMonth'] = df['RegistrationMonth'].replace(0, month_mode)\n    print(f\"Se reemplazaron los valores 0 de RegistrationMonth con {month_mode}.\")\nelse:\n    print(\"\\nNo se encontraron meses v\u00e1lidos (1-12) para calcular la moda.\")\n\n\n# --- Verificaci\u00f3n Post-Correcci\u00f3n ---\nprint(\"\\nEstad\u00edsticas descriptivas tras corregir anomal\u00edas:\")\ndisplay(df.describe())\n\nprint(\"\\nInformaci\u00f3n general tras corregir anomal\u00edas:\")\ndf.info() # Tambi\u00e9n revisamos info para ver si la limpieza afect\u00f3 los nulos"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nMuy bien con los filtros de la data. El rango v\u00e1lido utilizado me parece sensato, aunque tal vez hubiese sido mejor mirar la distribuci\u00f3n de la data antes del filtro.\n    \nRespecto a la correcci\u00f3n del mes, est\u00e1 bien, son relativamente pocas filas (6% aprox) a imputar. Adem\u00e1s, no estoy seguro que sea una variable tan \u00fatil para predecir. En general, no es bueno imputar con la moda (o media o mediana) de toda la data, puesto que podr\u00eda introducir un sesgo en los datos. Es mejor segmentar los datos e imputar los valores de cada grupo con la moda (u otro medida de tendencia central) de cada grupo. En este caso se me ocurre que tal vez hay ciertos veh\u00edculos que pueden tener estacionalidad en su venta como los descapotables, podr\u00eda haber sido una buena variable a explorar.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Tratamiento de Valores Nulos (NaN)\n\nLa limpieza anterior elimin\u00f3 filas con valores num\u00e9ricos an\u00f3malos, pero todav\u00eda tenemos valores ausentes (`NaN`) en cinco columnas categ\u00f3ricas (`VehicleType`, `Gearbox`, `Model`, `FuelType`, `NotRepaired`). Eliminar todas las filas con alg\u00fan valor nulo podr\u00eda resultar en una p\u00e9rdida considerable de datos (especialmente por `NotRepaired`, que tiene ~42k nulos).\n\n**Estrategia:**\n\nOptaremos por la **imputaci\u00f3n**, reemplazando los valores `NaN` con un valor constante que indique expl\u00edcitamente que la informaci\u00f3n estaba ausente. Usaremos la cadena de texto `'Unknown'` (o 'Desconocido'). Esta estrategia tiene dos ventajas:\n1.  Conserva todas las filas del dataset.\n2.  Permite que los modelos (especialmente los basados en \u00e1rboles como Random Forest, LightGBM, etc.) potencialmente aprendan si el hecho de que un valor sea desconocido es relevante para la predicci\u00f3n del precio.\n\n**Acciones:**\n1. Identificar las columnas categ\u00f3ricas con valores nulos.\n2. Reemplazar los `NaN` en estas columnas por la cadena `'Unknown'`.\n3. Verificar con `.info()` que ya no quedan valores nulos en el DataFrame.\n4. Opcionalmente, revisar los `value_counts()` de alguna columna modificada para ver la nueva categor\u00eda."}, {"cell_type": "code", "execution_count": 5, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Se imputaron los valores NaN en las columnas: VehicleType, Gearbox, Model, FuelType, NotRepaired con 'Unknown'.\n\nInformaci\u00f3n general tras imputar NaN:\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 294956 entries, 1 to 354368\nData columns (total 11 columns):\n #   Column             Non-Null Count   Dtype \n---  ------             --------------   ----- \n 0   Price              294956 non-null  int64 \n 1   VehicleType        294956 non-null  object\n 2   RegistrationYear   294956 non-null  int64 \n 3   Gearbox            294956 non-null  object\n 4   Power              294956 non-null  int64 \n 5   Model              294956 non-null  object\n 6   Mileage            294956 non-null  int64 \n 7   RegistrationMonth  294956 non-null  int64 \n 8   FuelType           294956 non-null  object\n 9   Brand              294956 non-null  object\n 10  NotRepaired        294956 non-null  object\ndtypes: int64(5), object(6)\nmemory usage: 27.0+ MB\n"}], "source": "# --- Imputaci\u00f3n de Valores Nulos ---\n# Columnas categ\u00f3ricas con nulos identificadas previamente\ncols_with_nan = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'NotRepaired']\n\n# Imputar NaN con 'Unknown'\nfor col in cols_with_nan:\n    df[col].fillna('Unknown', inplace=True)\n\nprint(f\"Se imputaron los valores NaN en las columnas: {', '.join(cols_with_nan)} con 'Unknown'.\")\n\n# --- Verificaci\u00f3n Post-Imputaci\u00f3n ---\nprint(\"\\nInformaci\u00f3n general tras imputar NaN:\")\ndf.info()\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nMuy bien, correcta la decisi\u00f3n\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "##  Preparaci\u00f3n de Datos para Modelado: Codificaci\u00f3n Diferenciada y Divisi\u00f3n\n\nAntes de entrenar los modelos, es crucial transformar nuestras caracter\u00edsticas para que sean adecuadas para los algoritmos de Machine Learning. Nuestra estrategia de codificaci\u00f3n ser\u00e1 diferenciada para manejar la alta cardinalidad de ciertas columnas y optimizar el n\u00famero final de caracter\u00edsticas:\n\n1.  **Codificar Caracter\u00edsticas Categ\u00f3ricas:**\n    * **`Brand` y `Model` :** Estas columnas tienen una gran cantidad de valores \u00fanicos. Aplicar One-Hot Encoding (OHE) directamente a ellas gener\u00f3 un n\u00famero muy elevado de caracter\u00edsticas, lo cual puede aumentar la complejidad y los tiempos de entrenamiento. Adem\u00e1s, estas caracter\u00edsticas tienen una naturaleza impl\u00edcitamente ordinal (ej. gamas de modelos, posicionamiento de marcas) que OHE no captura. Para manejar esto, aplicaremos **`OrdinalEncoder`** a `Brand` y `Model`. Esto transformar\u00e1 cada una de estas columnas en una \u00fanica columna de enteros, reduciendo significativamente la dimensionalidad. \n    * **Otras Categ\u00f3ricas (`VehicleType`, `Gearbox`, `FuelType`, `NotRepaired`):** Estas columnas tienen un n\u00famero mucho menor de categor\u00edas \u00fanicas. Para ellas, utilizaremos **`OneHotEncoder (OHE)`**, ya que es una t\u00e9cnica robusta que no impone un orden y funciona bien con la mayor\u00eda de los modelos.\n    * **Num\u00e9ricas:** Las caracter\u00edsticas que ya son num\u00e9ricas (`RegistrationYear`, `Power`, `Mileage`, `RegistrationMonth`) se mantendr\u00e1n sin cambios en este paso (`passthrough`).\n\n2.  **Dividir los Datos:** Como siempre, separaremos nuestro dataset en conjuntos de **entrenamiento** y **prueba** *antes* de aplicar cualquier codificaci\u00f3n para evitar la fuga de datos.\n\nUtilizaremos `train_test_split` para la divisi\u00f3n y `ColumnTransformer` para aplicar las diferentes estrategias de codificaci\u00f3n (`OrdinalEncoder` y `OneHotEncoder`) a los subconjuntos de columnas correspondientes, ajustando los codificadores \u00fanicamente con los datos de entrenamiento.\n\n**Acciones:**\n1. Separar las caracter\u00edsticas (`X`) de la variable objetivo (`y`, que es `Price`).\n2. Dividir `X` e `y` en conjuntos de entrenamiento y prueba.\n3. Identificar los diferentes grupos de columnas: num\u00e9ricas, categ\u00f3ricas de alta cardinalidad (`Brand`, `Model`), y categ\u00f3ricas de baja cardinalidad (las restantes).\n4. Crear y ajustar un `ColumnTransformer` que aplique `OrdinalEncoder` a las de alta cardinalidad, `OneHotEncoder` a las de baja cardinalidad, y deje las num\u00e9ricas como est\u00e1n.\n5. Transformar `X_train` y `X_test` usando el `ColumnTransformer` ajustado.\n6. Verificar las nuevas dimensiones de los conjuntos de datos resultantes."}, {"cell_type": "code", "execution_count": 12, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Caracter\u00edsticas Num\u00e9ricas: ['RegistrationYear', 'Power', 'Mileage', 'RegistrationMonth']\nCateg\u00f3ricas para OrdinalEncoding (Alta Cardinalidad): ['Brand', 'Model']\nCateg\u00f3ricas para OneHotEncoding (Baja Cardinalidad): ['VehicleType', 'Gearbox', 'FuelType', 'NotRepaired']\n\nDimensiones despu\u00e9s de la divisi\u00f3n y preprocesamiento ESTRAT\u00c9GICO:\nX_train_processed_strat shape: (221217, 29)\nX_test_processed_strat shape: (73739, 29)\ny_train shape: (221217,)\ny_test shape: (73739,)\n"}], "source": "# --- Separaci\u00f3n de Caracter\u00edsticas y Objetivo ---\nX = df.drop('Price', axis=1)\ny = df['Price']\n\n# --- Divisi\u00f3n en Conjuntos de Entrenamiento y Prueba ---\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# --- Identificaci\u00f3n de Tipos de Columnas para Codificaci\u00f3n Diferenciada ---\nnumerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n# Categor\u00edas a tratar con OrdinalEncoder\nhigh_card_categorical_features = ['Brand', 'Model']\n# Categor\u00edas a tratar con OneHotEncoder\nlow_card_categorical_features = [\n    col for col in X.select_dtypes(include='object').columns\n    if col not in high_card_categorical_features\n]\n\nprint(f\"Caracter\u00edsticas Num\u00e9ricas: {numerical_features}\")\nprint(f\"Categ\u00f3ricas para OrdinalEncoding (Alta Cardinalidad): {high_card_categorical_features}\")\nprint(f\"Categ\u00f3ricas para OneHotEncoding (Baja Cardinalidad): {low_card_categorical_features}\")\n\n# --- Creaci\u00f3n del Preprocesador con ColumnTransformer ---\npreprocessor_strat = make_column_transformer(\n    (OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), high_card_categorical_features),\n    (OneHotEncoder(handle_unknown='ignore', sparse=False), low_card_categorical_features),\n    remainder='passthrough') # Para las caracter\u00edsticas num\u00e9ricas\n\n\n# --- Ajuste y Transformaci\u00f3n ---\n\npreprocessor_strat.fit(X_train)\n\n# Transformar ambos conjuntos\nX_train_processed_strat = preprocessor_strat.transform(X_train)\nX_test_processed_strat = preprocessor_strat.transform(X_test)\n\n# --- Verificaci\u00f3n de Dimensiones ---\nprint(\"\\nDimensiones despu\u00e9s de la divisi\u00f3n y preprocesamiento ESTRAT\u00c9GICO:\")\nprint(f\"X_train_processed_strat shape: {X_train_processed_strat.shape}\")\nprint(f\"X_test_processed_strat shape: {X_test_processed_strat.shape}\")\nprint(f\"y_train shape: {y_train.shape}\") \nprint(f\"y_test shape: {y_test.shape}\")   "}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nExcelente, muy bien con esta preparaci\u00f3n de la data\n    \n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "##  Reevaluaci\u00f3n de Modelos con Codificaci\u00f3n Estrat\u00e9gica\n\nAhora que hemos procesado los datos con una codificaci\u00f3n diferenciada (`OrdinalEncoder` para `Brand` y `Model`, y `OneHotEncoder` para las otras categ\u00f3ricas), resultando en solo 29 caracter\u00edsticas, vamos a reentrenar nuestros modelos y comparar su rendimiento (RECM, tiempos) con los resultados obtenidos usando la codificaci\u00f3n OHE completa.\n\nComenzaremos, como siempre, con la Regresi\u00f3n Lineal.\n\n###  Modelo 1: Regresi\u00f3n Lineal (con Codificaci\u00f3n Estrat\u00e9gica)\n\nReentrenamos la Regresi\u00f3n Lineal usando `X_train_processed_strat` y `X_test_processed_strat`. Es importante notar que `OrdinalEncoder` asigna un orden num\u00e9rico arbitrario (por defecto) a `Brand` y `Model`. Los modelos lineales son sensibles a la magnitud y escala de estos n\u00fameros, por lo que este tipo de codificaci\u00f3n podr\u00eda no ser ideal para ellos si el orden no tiene una correlaci\u00f3n lineal real con el precio. Sin embargo, evaluaremos su rendimiento.\n\n**Acciones:**\n1. Crear una nueva lista para almacenar los resultados de esta estrategia.\n2. Crear una instancia del modelo `LinearRegression`.\n3. Medir el tiempo de entrenamiento.\n4. Medir el tiempo de predicci\u00f3n.\n5. Calcular el RECM.\n6. Almacenar y mostrar los resultados."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nEfectivamente, lo ideal es usar solamente one-hot encoding para un modelo como el de regresi\u00f3n lineal. De todos modos, me parece bien que lo menciones y que estes al tanto de las posibles limitaciones.\n    \n\n</div>"}, {"cell_type": "code", "execution_count": 16, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Iniciando entrenamiento de Linear Regression (Codificaci\u00f3n Estrat\u00e9gica)...\nEntrenamiento completado.\n\nResultados del Modelo: Linear Regression (Strategic Encoding)\nRMSE: 2868.2938\nTiempo de Entrenamiento: 0.1360 segundos\nTiempo de Predicci\u00f3n: 0.0740 segundos\n\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE</th>\n      <th>Training Time (s)</th>\n      <th>Prediction Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression (Strategic Enc.)</td>\n      <td>2868.293801</td>\n      <td>0.13603</td>\n      <td>0.074002</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                Model         RMSE  Training Time (s)  \\\n0  Linear Regression (Strategic Enc.)  2868.293801            0.13603   \n\n   Prediction Time (s)  \n0             0.074002  "}, "metadata": {}, "output_type": "display_data"}], "source": "# --- Nueva lista para resultados con codificaci\u00f3n estrat\u00e9gica ---\nresults_list_strat = []\n\n# --- Modelo 1: Linear Regression (Codificaci\u00f3n Estrat\u00e9gica) ---\nlr_model_strat = LinearRegression()\n\n# --- Entrenamiento ---\nprint(\"Iniciando entrenamiento de Linear Regression (Codificaci\u00f3n Estrat\u00e9gica)...\")\nstart_train_time = time.time()\nlr_model_strat.fit(X_train_processed_strat, y_train)\nend_train_time = time.time()\nlr_train_time_strat = end_train_time - start_train_time\nprint(\"Entrenamiento completado.\")\n\n# --- Predicci\u00f3n ---\nstart_pred_time = time.time()\ny_pred_lr_strat = lr_model_strat.predict(X_test_processed_strat)\nend_pred_time = time.time()\nlr_pred_time_strat = end_pred_time - start_pred_time\n\n# --- Evaluaci\u00f3n (RMSE) ---\nmse_lr_strat = mean_squared_error(y_test, y_pred_lr_strat)\nrmse_lr_strat = np.sqrt(mse_lr_strat)\n\n# --- Almacenar Resultados ---\nresults_list_strat.append({\n    'Model': 'Linear Regression (Strategic Enc.)',\n    'RMSE': rmse_lr_strat,\n    'Training Time (s)': lr_train_time_strat,\n    'Prediction Time (s)': lr_pred_time_strat\n})\n\n# --- Mostrar Resultados ---\nprint(\"\\nResultados del Modelo: Linear Regression (Strategic Encoding)\")\nprint(f\"RMSE: {rmse_lr_strat:.4f}\")\nprint(f\"Tiempo de Entrenamiento: {lr_train_time_strat:.4f} segundos\")\nprint(f\"Tiempo de Predicci\u00f3n: {lr_pred_time_strat:.4f} segundos\")\n\nresults_df_strat = pd.DataFrame(results_list_strat)\nprint(\"\\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\")\ndisplay(results_df_strat)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "###  Modelo 2: Bosque Aleatorio (con Codificaci\u00f3n Estrat\u00e9gica)\n\nReentrenamos el `RandomForestRegressor` utilizando los datos procesados con la codificaci\u00f3n estrat\u00e9gica (`X_train_processed_strat` y `X_test_processed_strat`). Utilizaremos los hiperpar\u00e1metros por defecto para esta primera evaluaci\u00f3n con los nuevos datos, y `n_jobs=-1` para acelerar el entrenamiento. \n**Acciones:**\n1. Crear una instancia del modelo `RandomForestRegressor`.\n2. Medir el tiempo de entrenamiento.\n3. Medir el tiempo de predicci\u00f3n.\n4. Calcular el RECM.\n5. Almacenar y mostrar los resultados, actualizando la tabla comparativa de la codificaci\u00f3n estrat\u00e9gica."}, {"cell_type": "code", "execution_count": 17, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Iniciando entrenamiento de Random Forest (Codificaci\u00f3n Estrat\u00e9gica)...\nEntrenamiento completado.\n\nResultados del Modelo: Random Forest (Strategic Encoding)\nRMSE: 1526.2562\nTiempo de Entrenamiento: 76.1050 segundos\nTiempo de Predicci\u00f3n: 2.3640 segundos\n\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE</th>\n      <th>Training Time (s)</th>\n      <th>Prediction Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression (Strategic Enc.)</td>\n      <td>2868.293801</td>\n      <td>0.136030</td>\n      <td>0.074002</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest (Strategic Enc.)</td>\n      <td>1526.256216</td>\n      <td>76.104985</td>\n      <td>2.364029</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                Model         RMSE  Training Time (s)  \\\n0  Linear Regression (Strategic Enc.)  2868.293801           0.136030   \n1      Random Forest (Strategic Enc.)  1526.256216          76.104985   \n\n   Prediction Time (s)  \n0             0.074002  \n1             2.364029  "}, "metadata": {}, "output_type": "display_data"}], "source": "# --- Modelo 2: Random Forest Regressor (Codificaci\u00f3n Estrat\u00e9gica) ---\nrf_model_strat = RandomForestRegressor(random_state=42, n_jobs=-1)\n\n# --- Entrenamiento ---\nprint(\"Iniciando entrenamiento de Random Forest (Codificaci\u00f3n Estrat\u00e9gica)...\")\nstart_train_time = time.time()\nrf_model_strat.fit(X_train_processed_strat, y_train)\nend_train_time = time.time()\nrf_train_time_strat = end_train_time - start_train_time\nprint(\"Entrenamiento completado.\")\n\n# --- Predicci\u00f3n ---\nstart_pred_time = time.time()\ny_pred_rf_strat = rf_model_strat.predict(X_test_processed_strat)\nend_pred_time = time.time()\nrf_pred_time_strat = end_pred_time - start_pred_time\n\n# --- Evaluaci\u00f3n (RMSE) ---\nmse_rf_strat = mean_squared_error(y_test, y_pred_rf_strat)\nrmse_rf_strat = np.sqrt(mse_rf_strat)\n\n# --- Almacenar Resultados ---\nresults_list_strat.append({\n    'Model': 'Random Forest (Strategic Enc.)',\n    'RMSE': rmse_rf_strat,\n    'Training Time (s)': rf_train_time_strat,\n    'Prediction Time (s)': rf_pred_time_strat\n})\n\n# --- Mostrar Resultados ---\nprint(\"\\nResultados del Modelo: Random Forest (Strategic Encoding)\")\nprint(f\"RMSE: {rmse_rf_strat:.4f}\")\nprint(f\"Tiempo de Entrenamiento: {rf_train_time_strat:.4f} segundos\")\nprint(f\"Tiempo de Predicci\u00f3n: {rf_pred_time_strat:.4f} segundos\")\n\nresults_df_strat = pd.DataFrame(results_list_strat)\nprint(\"\\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\")\ndisplay(results_df_strat)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "###  Modelo 3: LightGBM (con Codificaci\u00f3n Estrat\u00e9gica)\n\nEntrenamos `LightGBM` con los datos de 29 caracter\u00edsticas. Las dos primeras columnas de nuestros datos procesados (`X_train_processed_strat`) corresponden a `Brand` y `Model` codificadas ordinalmente. Le indicaremos a `LightGBM` que trate estas dos columnas como caracter\u00edsticas categ\u00f3ricas usando el par\u00e1metro `categorical_feature`. Las columnas restantes (resultado del OHE de las otras categ\u00f3ricas y las num\u00e9ricas originales) ser\u00e1n tratadas como num\u00e9ricas por defecto.\n\n**Acciones:**\n1. Identificar los \u00edndices de las columnas categ\u00f3ricas codificadas ordinalmente (Brand, Model).\n2. Crear una instancia del modelo `lgb.LGBMRegressor`, especificando `categorical_feature`.\n3. Medir el tiempo de entrenamiento.\n4. Medir el tiempo de predicci\u00f3n.\n5. Calcular el RECM.\n6. Almacenar y mostrar los resultados."}, {"cell_type": "code", "execution_count": 18, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Iniciando entrenamiento de LightGBM (Codificaci\u00f3n Estrat\u00e9gica)...\n"}, {"name": "stderr", "output_type": "stream", "text": "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/basic.py:1487: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\nPlease use categorical_feature argument of the Dataset constructor to pass this parameter.\n  _log_warning(f'{key} keyword has been found in `params` and will be ignored.\\n'\n"}, {"name": "stdout", "output_type": "stream", "text": "Entrenamiento completado.\n\nResultados del Modelo: LightGBM (Strategic Encoding)\nRMSE: 1572.6900\nTiempo de Entrenamiento: 2.8179 segundos\nTiempo de Predicci\u00f3n: 0.4848 segundos\n\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE</th>\n      <th>Training Time (s)</th>\n      <th>Prediction Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression (Strategic Enc.)</td>\n      <td>2868.293801</td>\n      <td>0.136030</td>\n      <td>0.074002</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest (Strategic Enc.)</td>\n      <td>1526.256216</td>\n      <td>76.104985</td>\n      <td>2.364029</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM (Strategic Enc.)</td>\n      <td>1572.690018</td>\n      <td>2.817937</td>\n      <td>0.484777</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                Model         RMSE  Training Time (s)  \\\n0  Linear Regression (Strategic Enc.)  2868.293801           0.136030   \n1      Random Forest (Strategic Enc.)  1526.256216          76.104985   \n2           LightGBM (Strategic Enc.)  1572.690018           2.817937   \n\n   Prediction Time (s)  \n0             0.074002  \n1             2.364029  \n2             0.484777  "}, "metadata": {}, "output_type": "display_data"}], "source": "# --- Modelo 3: LightGBM Regressor (Codificaci\u00f3n Estrat\u00e9gica) ---\n\ncategorical_feature_indices_for_lgbm = [0, 1]\n\nlgbm_model_strat = lgb.LGBMRegressor(\n    random_state=42,\n    n_jobs=-1,\n    categorical_feature=categorical_feature_indices_for_lgbm\n)\n\n# --- Entrenamiento ---\nprint(\"Iniciando entrenamiento de LightGBM (Codificaci\u00f3n Estrat\u00e9gica)...\")\nstart_train_time = time.time()\nlgbm_model_strat.fit(X_train_processed_strat, y_train)\nend_train_time = time.time()\nlgbm_train_time_strat = end_train_time - start_train_time\nprint(\"Entrenamiento completado.\")\n\n# --- Predicci\u00f3n ---\nstart_pred_time = time.time()\ny_pred_lgbm_strat = lgbm_model_strat.predict(X_test_processed_strat)\nend_pred_time = time.time()\nlgbm_pred_time_strat = end_pred_time - start_pred_time\n\n# --- Evaluaci\u00f3n (RMSE) ---\nmse_lgbm_strat = mean_squared_error(y_test, y_pred_lgbm_strat)\nrmse_lgbm_strat = np.sqrt(mse_lgbm_strat)\n\n# --- Almacenar Resultados ---\nresults_list_strat.append({\n    'Model': 'LightGBM (Strategic Enc.)',\n    'RMSE': rmse_lgbm_strat,\n    'Training Time (s)': lgbm_train_time_strat,\n    'Prediction Time (s)': lgbm_pred_time_strat\n})\n\n# --- Mostrar Resultados ---\nprint(\"\\nResultados del Modelo: LightGBM (Strategic Encoding)\")\nprint(f\"RMSE: {rmse_lgbm_strat:.4f}\")\nprint(f\"Tiempo de Entrenamiento: {lgbm_train_time_strat:.4f} segundos\")\nprint(f\"Tiempo de Predicci\u00f3n: {lgbm_pred_time_strat:.4f} segundos\")\n\nresults_df_strat = pd.DataFrame(results_list_strat)\nprint(\"\\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\")\ndisplay(results_df_strat)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nMuy bien con el entrenamiento y resultado de los modelos, buen trabajo!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "## An\u00e1lisis del modelo\n\n Ajuste de Hiperpar\u00e1metros (con Codificaci\u00f3n Estrat\u00e9gica)\n\nCon los datos procesados estrat\u00e9gicamente (29 caracter\u00edsticas), procederemos a ajustar los hiperpar\u00e1metros de Random Forest. Esta vez utilizaremos `GridSearchCV` para una b\u00fasqueda exhaustiva dentro de una cuadr\u00edcula definida de par\u00e1metros. Dado el menor n\u00famero de caracter\u00edsticas, esperamos que el tiempo de ejecuci\u00f3n sea aceptable.\n\n### Ajuste de Hiperpar\u00e1metros: Random Forest (Estrat\u00e9gico - GridSearchCV)\n\n**Acciones:**\n1. Definir una cuadr\u00edcula de hiperpar\u00e1metros (`param_grid`) para `RandomForestRegressor`.\n2. Configurar la validaci\u00f3n cruzada (usaremos `KFold` con 3 divisiones).\n3. Crear e iniciar `GridSearchCV` usando `scoring='neg_mean_squared_error'`.\n4. Entrenar el `GridSearchCV`.\n5. Obtener los mejores par\u00e1metros y el mejor RECM de la validaci\u00f3n cruzada.\n6. Entrenar un modelo final `RandomForestRegressor` con los mejores par\u00e1metros encontrados.\n7. Evaluar este modelo final en el conjunto de prueba y medir tiempos.\n8. Almacenar y mostrar los resultados del modelo ajustado."}, {"cell_type": "code", "execution_count": 19, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Iniciando GridSearchCV para RF (Estrat\u00e9gico)... Probando 16 combinaciones x 3 folds = 48 fits.\nFitting 3 folds for each of 16 candidates, totalling 48 fits\nGridSearchCV para RF (Estrat\u00e9gico) completado en 2585.18 segundos.\n\nMejores par\u00e1metros encontrados (RF Estrat\u00e9gico - GridSearchCV): {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\nMejor RMSE (cross-validation, 3 folds): 1590.6051\n\nEntrenando modelo final RF (Estrat\u00e9gico) con los mejores par\u00e1metros de GridSearchCV...\nEntrenamiento final completado.\n\nResultados del Modelo: Random Forest (Tuned - Strat. GS) en Test Set\nRMSE: 1507.0833\nTiempo de Entrenamiento Final: 87.5693 segundos\nTiempo de Predicci\u00f3n: 2.0576 segundos\n\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE</th>\n      <th>Training Time (s)</th>\n      <th>Prediction Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression (Strategic Enc.)</td>\n      <td>2868.293801</td>\n      <td>0.136030</td>\n      <td>0.074002</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest (Strategic Enc.)</td>\n      <td>1526.256216</td>\n      <td>76.104985</td>\n      <td>2.364029</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM (Strategic Enc.)</td>\n      <td>1572.690018</td>\n      <td>2.817937</td>\n      <td>0.484777</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest (Tuned - Strat. GS)</td>\n      <td>1507.083333</td>\n      <td>87.569270</td>\n      <td>2.057618</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                Model         RMSE  Training Time (s)  \\\n0  Linear Regression (Strategic Enc.)  2868.293801           0.136030   \n1      Random Forest (Strategic Enc.)  1526.256216          76.104985   \n2           LightGBM (Strategic Enc.)  1572.690018           2.817937   \n3   Random Forest (Tuned - Strat. GS)  1507.083333          87.569270   \n\n   Prediction Time (s)  \n0             0.074002  \n1             2.364029  \n2             0.484777  \n3             2.057618  "}, "metadata": {}, "output_type": "display_data"}], "source": "# --- Ajuste de Hiperpar\u00e1metros: Random Forest (Codificaci\u00f3n Estrat\u00e9gica - GridSearchCV) ---\nfrom sklearn.model_selection import GridSearchCV # Aseg\u00farate de importar\nfrom sklearn.model_selection import KFold # Aseg\u00farate de importar\n\n# Definir una cuadr\u00edcula de par\u00e1metros para probar con GridSearchCV\nparam_grid_rf_gs = {\n    'n_estimators': [100, 150],\n    'max_depth': [20, None],\n    'min_samples_split': [2, 5],\n    'min_samples_leaf': [1, 3]\n}\n# Total combinaciones = 2 * 2 * 2 * 2 = 16\n\n# Configurar Validaci\u00f3n Cruzada (KFold con 3 splits)\ncv_strategy_gs_rf = KFold(n_splits=3, shuffle=True, random_state=42)\n\n# Crear el objeto GridSearchCV\ngrid_search_rf_strat = GridSearchCV(\n    estimator=RandomForestRegressor(random_state=42, n_jobs=-1),\n    param_grid=param_grid_rf_gs,\n    cv=cv_strategy_gs_rf,\n    scoring='neg_mean_squared_error',\n    verbose=1,\n    n_jobs=-1\n)\n\n# --- Ejecutar la B\u00fasqueda en Cuadr\u00edcula ---\nnum_combinations = (len(param_grid_rf_gs['n_estimators']) *\n                  len(param_grid_rf_gs['max_depth']) *\n                  len(param_grid_rf_gs['min_samples_split']) *\n                  len(param_grid_rf_gs['min_samples_leaf']))\nnum_fits = num_combinations * cv_strategy_gs_rf.get_n_splits()\n\nprint(f\"Iniciando GridSearchCV para RF (Estrat\u00e9gico)... Probando {num_combinations} combinaciones x {cv_strategy_gs_rf.get_n_splits()} folds = {num_fits} fits.\")\nstart_grid_time = time.time()\n# Usamos los datos con codificaci\u00f3n estrat\u00e9gica\ngrid_search_rf_strat.fit(X_train_processed_strat, y_train)\nend_grid_time = time.time()\ngrid_search_rf_time = end_grid_time - start_grid_time\nprint(f\"GridSearchCV para RF (Estrat\u00e9gico) completado en {grid_search_rf_time:.2f} segundos.\")\n\n# --- Obtener Mejores Par\u00e1metros y Puntuaci\u00f3n CV ---\nbest_params_rf_strat = grid_search_rf_strat.best_params_\nbest_score_rf_cv_strat = grid_search_rf_strat.best_score_\nbest_rmse_rf_cv_strat = np.sqrt(-best_score_rf_cv_strat)\n\nprint(f\"\\nMejores par\u00e1metros encontrados (RF Estrat\u00e9gico - GridSearchCV): {best_params_rf_strat}\")\nprint(f\"Mejor RMSE (cross-validation, {cv_strategy_gs_rf.get_n_splits()} folds): {best_rmse_rf_cv_strat:.4f}\")\n\n# --- Entrenar Modelo Final con Mejores Par\u00e1metros ---\nprint(\"\\nEntrenando modelo final RF (Estrat\u00e9gico) con los mejores par\u00e1metros de GridSearchCV...\")\nfinal_rf_model_strat = RandomForestRegressor(**best_params_rf_strat, random_state=42, n_jobs=-1)\n\nstart_train_time = time.time()\nfinal_rf_model_strat.fit(X_train_processed_strat, y_train)\nend_train_time = time.time()\nfinal_rf_train_time_strat = end_train_time - start_train_time\nprint(\"Entrenamiento final completado.\")\n\n# --- Predicci\u00f3n y Evaluaci\u00f3n del Modelo Final en Test ---\nstart_pred_time = time.time()\ny_pred_final_rf_strat = final_rf_model_strat.predict(X_test_processed_strat)\nend_pred_time = time.time()\nfinal_rf_pred_time_strat = end_pred_time - start_pred_time\n\nmse_final_rf_strat = mean_squared_error(y_test, y_pred_final_rf_strat)\nrmse_final_rf_strat = np.sqrt(mse_final_rf_strat)\n\n# --- Actualizar Resultados ---\n\nresults_list_strat = [res for res in results_list_strat if 'Random Forest (Tuned' not in res['Model']]\nresults_list_strat.append({\n    'Model': 'Random Forest (Tuned - Strat. GS)', # GS para GridSearchCV\n    'RMSE': rmse_final_rf_strat,\n    'Training Time (s)': final_rf_train_time_strat,\n    'Prediction Time (s)': final_rf_pred_time_strat\n})\n\n# --- Mostrar Resultados ---\nprint(\"\\nResultados del Modelo: Random Forest (Tuned - Strat. GS) en Test Set\")\nprint(f\"RMSE: {rmse_final_rf_strat:.4f}\")\nprint(f\"Tiempo de Entrenamiento Final: {final_rf_train_time_strat:.4f} segundos\")\nprint(f\"Tiempo de Predicci\u00f3n: {final_rf_pred_time_strat:.4f} segundos\")\n\nresults_df_strat = pd.DataFrame(results_list_strat)\nprint(\"\\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\")\ndisplay(results_df_strat)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Ajuste de Hiperpar\u00e1metros: LightGBM (Estrat\u00e9gico - con Manejo de Categor\u00edas Simplificado)\n\nPara ajustar LightGBM y facilitar que maneje correctamente las caracter\u00edsticas `Brand` y `Model` (codificadas ordinalmente) como categ\u00f3ricas, convertiremos nuestras matrices de caracter\u00edsticas procesadas a DataFrames de pandas. Usaremos nombres gen\u00e9ricos para las columnas y luego cambiaremos el tipo de dato de las dos primeras columnas (correspondientes a `Brand` y `Model`) a `category`. LightGBM deber\u00eda poder auto-detectar estas columnas de tipo `category`. Utilizaremos `RandomizedSearchCV` para la b\u00fasqueda de hiperpar\u00e1metros.\n\n**Acciones:**\n1. Crear nombres de caracter\u00edsticas gen\u00e9ricos.\n2. Convertir `X_train_processed_strat` y `X_test_processed_strat` a DataFrames de pandas con estos nombres.\n3. Cambiar el tipo de dato de las dos primeras columnas (representando `Brand` y `Model`) a `category`.\n4. Definir un espacio de b\u00fasqueda de hiperpar\u00e1metros para `LGBMRegressor`.\n5. Configurar y ejecutar `RandomizedSearchCV`.\n6. Obtener los mejores par\u00e1metros y el RECM de validaci\u00f3n cruzada.\n7. Entrenar un modelo final `LGBMRegressor` con los mejores par\u00e1metros.\n8. Evaluar en el conjunto de prueba y medir tiempos.\n9. Almacenar y mostrar resultados."}, {"cell_type": "code", "execution_count": 22, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Columnas a convertir a 'category': ['feat_0', 'feat_1']\n\nTipos de datos en X_train_df_strat despu\u00e9s de conversi\u00f3n (primeras 5 columnas):\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 221217 entries, 293100 to 146371\nData columns (total 5 columns):\n #   Column  Non-Null Count   Dtype   \n---  ------  --------------   -----   \n 0   feat_0  221217 non-null  category\n 1   feat_1  221217 non-null  category\n 2   feat_2  221217 non-null  float64 \n 3   feat_3  221217 non-null  float64 \n 4   feat_4  221217 non-null  float64 \ndtypes: category(2), float64(3)\nmemory usage: 7.4 MB\n\nIniciando RandomizedSearchCV para LightGBM (Estrat\u00e9gico)... Probando 15 combinaciones x 3 folds.\nFitting 3 folds for each of 15 candidates, totalling 45 fits\nRandomizedSearchCV para LightGBM (Estrat\u00e9gico) completado en 6600.33 segundos.\n\nMejores par\u00e1metros encontrados (LightGBM Estrat\u00e9gico): {'subsample': 0.8, 'num_leaves': 40, 'n_estimators': 400, 'max_depth': -1, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\nMejor RMSE (cross-validation): 1541.1110\n\nEntrenando modelo final LightGBM (Estrat\u00e9gico) con los mejores par\u00e1metros...\nEntrenamiento final completado.\n\nResultados del Modelo: LightGBM (Tuned - Strat.) en Test Set\nRMSE: 1493.5485\nTiempo de Entrenamiento Final: 7.4110 segundos\nTiempo de Predicci\u00f3n: 2.0042 segundos\n\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE</th>\n      <th>Training Time (s)</th>\n      <th>Prediction Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression (Strategic Enc.)</td>\n      <td>2868.293801</td>\n      <td>0.136030</td>\n      <td>0.074002</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest (Strategic Enc.)</td>\n      <td>1526.256216</td>\n      <td>76.104985</td>\n      <td>2.364029</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM (Strategic Enc.)</td>\n      <td>1572.690018</td>\n      <td>2.817937</td>\n      <td>0.484777</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest (Tuned - Strat. GS)</td>\n      <td>1507.083333</td>\n      <td>87.569270</td>\n      <td>2.057618</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBM (Tuned - Strat.)</td>\n      <td>1493.548506</td>\n      <td>7.410981</td>\n      <td>2.004156</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                Model         RMSE  Training Time (s)  \\\n0  Linear Regression (Strategic Enc.)  2868.293801           0.136030   \n1      Random Forest (Strategic Enc.)  1526.256216          76.104985   \n2           LightGBM (Strategic Enc.)  1572.690018           2.817937   \n3   Random Forest (Tuned - Strat. GS)  1507.083333          87.569270   \n4           LightGBM (Tuned - Strat.)  1493.548506           7.410981   \n\n   Prediction Time (s)  \n0             0.074002  \n1             2.364029  \n2             0.484777  \n3             2.057618  \n4             2.004156  "}, "metadata": {}, "output_type": "display_data"}], "source": "# --- Preparaci\u00f3n de Datos Simplificada para LightGBM con Dtype 'category' ---\nn_features_strat = X_train_processed_strat.shape[1]\n\n# Crear nombres de caracter\u00edsticas gen\u00e9ricos\ngeneric_feature_names = [f'feat_{i}' for i in range(n_features_strat)]\n\n# Convertir a DataFrames\nX_train_df_strat = pd.DataFrame(X_train_processed_strat, columns=generic_feature_names, index=X_train.index)\nX_test_df_strat = pd.DataFrame(X_test_processed_strat, columns=generic_feature_names, index=X_test.index)\n\n# Las dos primeras columnas ('feat_0', 'feat_1') corresponden a Brand y Model\nbrand_model_col_names = generic_feature_names[:2]\n\nprint(f\"Columnas a convertir a 'category': {brand_model_col_names}\")\nfor col_name in brand_model_col_names:\n    X_train_df_strat[col_name] = X_train_df_strat[col_name].astype('category')\n    X_test_df_strat[col_name] = X_test_df_strat[col_name].astype('category')\n\nprint(\"\\nTipos de datos en X_train_df_strat despu\u00e9s de conversi\u00f3n (primeras 5 columnas):\")\n# Mostramos info de las primeras 5 columnas para verificar el tipo 'category' en las dos primeras\nX_train_df_strat.iloc[:, :5].info()\n\n\n# --- Ajuste de Hiperpar\u00e1metros: LightGBM ---\n\nparam_dist_lgbm = {\n    'n_estimators': [100, 200, 300, 400],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'num_leaves': [20, 31, 40, 50],\n    'max_depth': [-1, 10, 20],\n    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n    'subsample': [0.7, 0.8, 0.9, 1.0]\n}\nn_iter_search_lgbm = 15 \ncv_strategy_lgbm = KFold(n_splits=3, shuffle=True, random_state=42)\n\nrandom_search_lgbm_strat = RandomizedSearchCV(\n    estimator=lgb.LGBMRegressor(random_state=42, n_jobs=-1),\n    param_distributions=param_dist_lgbm,\n    n_iter=n_iter_search_lgbm,\n    cv=cv_strategy_lgbm,\n    scoring='neg_mean_squared_error',\n    verbose=1,\n    random_state=42,\n    n_jobs=-1\n)\n\n# --- Ejecutar la B\u00fasqueda Aleatoria ---\nprint(f\"\\nIniciando RandomizedSearchCV para LightGBM (Estrat\u00e9gico)... Probando {n_iter_search_lgbm} combinaciones x {cv_strategy_lgbm.get_n_splits()} folds.\")\nstart_random_time = time.time()\nrandom_search_lgbm_strat.fit(X_train_df_strat, y_train)\nend_random_time = time.time()\nrandom_search_lgbm_time = end_random_time - start_random_time\nprint(f\"RandomizedSearchCV para LightGBM (Estrat\u00e9gico) completado en {random_search_lgbm_time:.2f} segundos.\")\n\n# --- Obtener Mejores Par\u00e1metros y Puntuaci\u00f3n CV ---\nbest_params_lgbm_strat = random_search_lgbm_strat.best_params_\nbest_score_lgbm_cv_strat = random_search_lgbm_strat.best_score_\nbest_rmse_lgbm_cv_strat = np.sqrt(-best_score_lgbm_cv_strat)\n\nprint(f\"\\nMejores par\u00e1metros encontrados (LightGBM Estrat\u00e9gico): {best_params_lgbm_strat}\")\nprint(f\"Mejor RMSE (cross-validation): {best_rmse_lgbm_cv_strat:.4f}\")\n\n# --- Entrenar Modelo Final con Mejores Par\u00e1metros ---\nprint(\"\\nEntrenando modelo final LightGBM (Estrat\u00e9gico) con los mejores par\u00e1metros...\")\nfinal_lgbm_model_strat = lgb.LGBMRegressor(**best_params_lgbm_strat, random_state=42, n_jobs=-1)\n\nstart_train_time = time.time()\nfinal_lgbm_model_strat.fit(X_train_df_strat, y_train)\nend_train_time = time.time()\nfinal_lgbm_train_time_strat = end_train_time - start_train_time\nprint(\"Entrenamiento final completado.\")\n\n# --- Predicci\u00f3n y Evaluaci\u00f3n del Modelo Final en Test ---\nstart_pred_time = time.time()\ny_pred_final_lgbm_strat = final_lgbm_model_strat.predict(X_test_df_strat)\nend_pred_time = time.time()\nfinal_lgbm_pred_time_strat = end_pred_time - start_pred_time\n\nmse_final_lgbm_strat = mean_squared_error(y_test, y_pred_final_lgbm_strat)\nrmse_final_lgbm_strat = np.sqrt(mse_final_lgbm_strat)\n\n# --- Actualizar Resultados ---\nresults_list_strat = [res for res in results_list_strat if 'LightGBM (Tuned' not in res['Model']]\nresults_list_strat.append({\n    'Model': 'LightGBM (Tuned - Strat.)',\n    'RMSE': rmse_final_lgbm_strat,\n    'Training Time (s)': final_lgbm_train_time_strat,\n    'Prediction Time (s)': final_lgbm_pred_time_strat\n})\n\n# --- Mostrar Resultados ---\nprint(\"\\nResultados del Modelo: LightGBM (Tuned - Strat.) en Test Set\")\nprint(f\"RMSE: {rmse_final_lgbm_strat:.4f}\")\nprint(f\"Tiempo de Entrenamiento Final: {final_lgbm_train_time_strat:.4f} segundos\")\nprint(f\"Tiempo de Predicci\u00f3n: {final_lgbm_pred_time_strat:.4f} segundos\")\n\nresults_df_strat = pd.DataFrame(results_list_strat)\nprint(\"\\nTabla Comparativa de Resultados (Codificaci\u00f3n Estrat\u00e9gica):\")\ndisplay(results_df_strat)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nExcelente trabajo, muy bien con la secci\u00f3n de tuning de los modelos, el c\u00f3digo est\u00e1 ordenado y utilizas adecuadamente los m\u00e9todos correctos.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "## An\u00e1lisis Final de Modelos y Selecci\u00f3n\n\nHemos llegado al punto de analizar los resultados consolidados de todos los modelos entrenados y ajustados utilizando nuestra estrategia de codificaci\u00f3n final (29 caracter\u00edsticas, con `OrdinalEncoder` para `Brand` y `Model`, y `OneHotEncoder` para las dem\u00e1s categ\u00f3ricas). Rusty Bargain est\u00e1 interesado en tres aspectos principales: la calidad de la predicci\u00f3n (RECM), la velocidad de predicci\u00f3n y el tiempo requerido para el entrenamiento.\n\nLa siguiente tabla resume el rendimiento de los modelos evaluados bajo esta estrategia:"}, {"cell_type": "code", "execution_count": 23, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tabla Final de Resultados (Codificaci\u00f3n Estrat\u00e9gica - 29 caracter\u00edsticas):\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE</th>\n      <th>Training Time (s)</th>\n      <th>Prediction Time (s)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>LightGBM (Tuned - Strat.)</td>\n      <td>1493.548506</td>\n      <td>7.410981</td>\n      <td>2.004156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest (Tuned - Strat. GS)</td>\n      <td>1507.083333</td>\n      <td>87.569270</td>\n      <td>2.057618</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest (Strategic Enc.)</td>\n      <td>1526.256216</td>\n      <td>76.104985</td>\n      <td>2.364029</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM (Strategic Enc.)</td>\n      <td>1572.690018</td>\n      <td>2.817937</td>\n      <td>0.484777</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Linear Regression (Strategic Enc.)</td>\n      <td>2868.293801</td>\n      <td>0.136030</td>\n      <td>0.074002</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                Model         RMSE  Training Time (s)  \\\n4           LightGBM (Tuned - Strat.)  1493.548506           7.410981   \n3   Random Forest (Tuned - Strat. GS)  1507.083333          87.569270   \n1      Random Forest (Strategic Enc.)  1526.256216          76.104985   \n2           LightGBM (Strategic Enc.)  1572.690018           2.817937   \n0  Linear Regression (Strategic Enc.)  2868.293801           0.136030   \n\n   Prediction Time (s)  \n4             2.004156  \n3             2.057618  \n1             2.364029  \n2             0.484777  \n0             0.074002  "}, "metadata": {}, "output_type": "display_data"}], "source": "# --- Mostrar la Tabla Final de Resultados de la Codificaci\u00f3n Estrat\u00e9gica ---\nprint(\"Tabla Final de Resultados (Codificaci\u00f3n Estrat\u00e9gica - 29 caracter\u00edsticas):\")\ndisplay(results_df_strat.sort_values(by='RMSE'))"}, {"cell_type": "markdown", "metadata": {}, "source": "**Discusi\u00f3n Comparativa:**\n\n1.  **Calidad de la Predicci\u00f3n (RECM):**\n    * El modelo `LightGBM (Tuned - Strat.)` claramente ofrece el **menor RECM (aproximadamente 1493.55\u20ac)**, lo que indica la mayor precisi\u00f3n en la predicci\u00f3n de precios.\n    * Le sigue de cerca el `Random Forest (Tuned - Strat. GS)` con un RECM de aproximadamente 1507.08\u20ac. La diferencia es relativamente peque\u00f1a, pero LightGBM tiene la ventaja.\n    * Ambos modelos ajustados superan a sus versiones con par\u00e1metros por defecto.\n    * La `Linear Regression (Strategic Enc.)` tuvo un rendimiento significativamente inferior (RECM ~2868\u20ac), lo que confirma que las relaciones en los datos son complejas y no lineales, y que el manejo de `Brand` y `Model` como n\u00fameros ordinales arbitrarios no fue beneficioso para este modelo.\n\n2.  **Tiempo de Entrenamiento (del modelo final, post-ajuste):**\n    * `LightGBM (Tuned - Strat.)` es el claro ganador aqu\u00ed entre los modelos de alto rendimiento, con un tiempo de entrenamiento final de solo **~7.4 segundos**.\n    * `Random Forest (Tuned - Strat. GS)` requiri\u00f3 **~87.6 segundos** para entrenar el modelo final, m\u00e1s de 10 veces el tiempo de LightGBM.\n    * `Linear Regression (Strategic Enc.)` fue el m\u00e1s r\u00e1pido en entrenar (~0.14 segundos), pero su baja precisi\u00f3n lo descarta.\n    * Es importante notar que los tiempos de b\u00fasqueda de hiperpar\u00e1metros (`RandomizedSearchCV` o `GridSearchCV`) fueron considerablemente m\u00e1s largos (especialmente para LightGBM en este caso, ~110 min, y RF ~43 min). Este es un costo \u00fanico durante la fase de desarrollo del modelo.\n\n3.  **Velocidad de Predicci\u00f3n:**\n    * `Linear Regression (Strategic Enc.)` es la m\u00e1s r\u00e1pida (~0.07 segundos).\n    * `LightGBM (Strategic Enc.)` con par\u00e1metros por defecto fue muy r\u00e1pido (~0.48 segundos).\n    * `LightGBM (Tuned - Strat.)` y `Random Forest (Tuned - Strat. GS)` tienen tiempos de predicci\u00f3n muy competitivos y similares, alrededor de **~2.0 segundos** para el conjunto de prueba. Esta velocidad es probablemente muy aceptable para una aplicaci\u00f3n que necesita averiguar r\u00e1pidamente el valor de mercado.\n\n**Selecci\u00f3n del Mejor Modelo para Rusty Bargain:**\n\nConsiderando los tres criterios:\n\n* **`LightGBM (Tuned - Strat.)`** emerge como el modelo m\u00e1s equilibrado y, en general, el **mejor candidato**.\n    * Ofrece el **RECM m\u00e1s bajo (mejor precisi\u00f3n)**.\n    * Su **tiempo de entrenamiento final es excepcionalmente r\u00e1pido**.\n    * Su **velocidad de predicci\u00f3n es muy buena** y competitiva.\n\nSi bien el tiempo de b\u00fasqueda de hiperpar\u00e1metros para LightGBM fue largo, este es un proceso que se realiza una sola vez (o infrecuentemente) para encontrar los mejores par\u00e1metros. Una vez encontrados, el reentrenamiento del modelo (si es necesario con nuevos datos) es muy r\u00e1pido.\n\nEl `Random Forest (Tuned - Strat. GS)` es una alternativa s\u00f3lida, con una precisi\u00f3n casi tan buena, pero es notablemente m\u00e1s lento en el entrenamiento del modelo final.\n\n**Recomendaci\u00f3n:**\nSe recomienda el modelo **`LightGBM (Tuned - Strat.)`** con los hiperpar\u00e1metros encontrados: `{'subsample': 0.8, 'num_leaves': 40, 'n_estimators': 400, 'max_depth': -1, 'learning_rate': 0.1, 'colsample_bytree': 1.0}`. Ofrece la mejor combinaci\u00f3n de alta precisi\u00f3n, r\u00e1pido entrenamiento del modelo final y r\u00e1pida velocidad de predicci\u00f3n."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nMuy bien! De acuerdo con los an\u00e1lisis, son de gran calidad. Haces muy bien en realizar la comparativa en los tiempos y calidad del modelo.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Conclusi\u00f3n del Proyecto\n\nEn este proyecto, hemos desarrollado y evaluado varios modelos de Machine Learning con el objetivo de predecir el valor de mercado de coches de segunda mano para el servicio Rusty Bargain. El proceso incluy\u00f3 una exhaustiva limpieza y preprocesamiento de datos, la exploraci\u00f3n de diferentes estrategias de codificaci\u00f3n de caracter\u00edsticas y el entrenamiento y ajuste de m\u00faltiples algoritmos de regresi\u00f3n.\n\n**Proceso y Hallazgos Clave:**\n\n1.  **Preparaci\u00f3n de Datos:** Se cargaron los datos, se realiz\u00f3 una limpieza inicial eliminando duplicados y columnas irrelevantes. Se trataron valores an\u00f3malos en caracter\u00edsticas num\u00e9ricas clave como `Price`, `RegistrationYear` y `Power`. Los valores nulos en columnas categ\u00f3ricas fueron imputados con la etiqueta \"Unknown\".\n2.  **Codificaci\u00f3n de Caracter\u00edsticas:** Se implement\u00f3 una **codificaci\u00f3n estrat\u00e9gica** m\u00e1s eficiente: `OrdinalEncoder` para `Brand` y `Model` (alta cardinalidad) y `OneHotEncoder` para las dem\u00e1s categ\u00f3ricas (baja cardinalidad), resultando en un conjunto de datos manejable de **29 caracter\u00edsticas**. Se prepararon los datos para LightGBM asegurando que las columnas `Brand` y `Model` codificadas ordinalmente fueran tratadas como tipo `category` para un manejo \u00f3ptimo.\n3.  **Modelado y Evaluaci\u00f3n:** Se entrenaron y evaluaron modelos de Regresi\u00f3n Lineal, Random Forest y LightGBM. Se realiz\u00f3 un ajuste de hiperpar\u00e1metros para Random Forest (usando `GridSearchCV`) y LightGBM (usando `RandomizedSearchCV`) sobre los datos con codificaci\u00f3n estrat\u00e9gica.\n    * Los modelos basados en \u00e1rboles (Random Forest y LightGBM) superaron ampliamente a la Regresi\u00f3n Lineal en precisi\u00f3n.\n    * La codificaci\u00f3n estrat\u00e9gica (29 caracter\u00edsticas) demostr\u00f3 ser muy efectiva, logrando precisiones comparables (e incluso mejores despu\u00e9s del ajuste) a las obtenidas con OHE completo, pero con tiempos de entrenamiento y predicci\u00f3n significativamente m\u00e1s r\u00e1pidos para los modelos de ensamble.\n    * El ajuste de hiperpar\u00e1metros fue crucial para exprimir el m\u00e1ximo rendimiento de Random Forest y LightGBM.\n\n**Modelo Recomendado:**\n\nEl modelo **`LightGBM (Tuned - Strat.)`** con los hiperpar\u00e1metros `{'subsample': 0.8, 'num_leaves': 40, 'n_estimators': 400, 'max_depth': -1, 'learning_rate': 0.1, 'colsample_bytree': 1.0}` es el recomendado. Logr\u00f3 el mejor rendimiento en t\u00e9rminos de **RECM (1493.55\u20ac)**, combinado con un **tiempo de entrenamiento del modelo final muy r\u00e1pido (7.4 segundos)** y una **excelente velocidad de predicci\u00f3n (2.0 segundos)** para el conjunto de prueba.\n\nEste modelo cumple con los requisitos de Rusty Bargain de alta calidad de predicci\u00f3n, velocidad de predicci\u00f3n y un tiempo de entrenamiento eficiente (para el modelo final).\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n\nExcelentes conclusiones. Haces muy bien al incluir valores de las m\u00e9tricas muy importantes y resumes los principales hallazgos, buen trabajo!\n    \n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "# Lista de control"}, {"cell_type": "markdown", "metadata": {}, "source": "Escribe 'x' para verificar. Luego presiona Shift+Enter"}, {"cell_type": "markdown", "metadata": {}, "source": "- [x]  Jupyter Notebook est\u00e1 abierto\n- [ ]  El c\u00f3digo no tiene errores- [ ]  Las celdas con el c\u00f3digo han sido colocadas en orden de ejecuci\u00f3n- [ ]  Los datos han sido descargados y preparados- [ ]  Los modelos han sido entrenados\n- [ ]  Se realiz\u00f3 el an\u00e1lisis de velocidad y calidad de los modelos"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": ""}], "metadata": {"ExecuteTimeLog": [{"duration": 2912, "start_time": "2025-04-23T15:36:38.378Z"}, {"duration": 837, "start_time": "2025-04-23T15:38:24.694Z"}, {"duration": 158, "start_time": "2025-04-24T01:56:21.516Z"}, {"duration": 2755, "start_time": "2025-04-24T01:56:27.889Z"}, {"duration": 1044, "start_time": "2025-04-24T01:56:34.426Z"}, {"duration": 191, "start_time": "2025-04-29T03:08:56.337Z"}, {"duration": 3784, "start_time": "2025-04-29T03:09:04.246Z"}, {"duration": 1061, "start_time": "2025-04-29T03:09:08.033Z"}, {"duration": 454, "start_time": "2025-04-29T03:09:09.102Z"}, {"duration": 2895, "start_time": "2025-04-30T01:15:15.799Z"}, {"duration": 895, "start_time": "2025-04-30T01:15:18.696Z"}, {"duration": 373, "start_time": "2025-04-30T01:15:19.593Z"}, {"duration": 180, "start_time": "2025-04-30T01:17:09.621Z"}, {"duration": 2787, "start_time": "2025-05-01T02:17:36.408Z"}, {"duration": 815, "start_time": "2025-05-01T02:17:39.198Z"}, {"duration": 337, "start_time": "2025-05-01T02:17:40.015Z"}, {"duration": 177, "start_time": "2025-05-01T02:17:40.354Z"}, {"duration": 2868, "start_time": "2025-05-02T01:58:16.249Z"}, {"duration": 860, "start_time": "2025-05-02T01:58:19.120Z"}, {"duration": 349, "start_time": "2025-05-02T01:58:19.982Z"}, {"duration": 181, "start_time": "2025-05-02T01:58:20.333Z"}, {"duration": 117, "start_time": "2025-05-02T02:09:50.132Z"}, {"duration": 94, "start_time": "2025-05-02T02:10:55.512Z"}, {"duration": 461, "start_time": "2025-05-02T02:24:37.788Z"}, {"duration": 336, "start_time": "2025-05-02T02:26:07.403Z"}, {"duration": 172, "start_time": "2025-05-02T02:27:08.621Z"}, {"duration": 1532, "start_time": "2025-05-02T02:28:44.099Z"}, {"duration": 10019, "start_time": "2025-05-02T02:48:17.717Z"}, {"duration": 293582, "start_time": "2025-05-02T02:51:51.170Z"}, {"duration": 77713, "start_time": "2025-05-02T03:00:18.955Z"}, {"duration": 1135, "start_time": "2025-05-02T03:49:13.487Z"}, {"duration": 873, "start_time": "2025-05-02T03:49:14.624Z"}, {"duration": 361, "start_time": "2025-05-02T03:49:15.499Z"}, {"duration": 188, "start_time": "2025-05-02T03:49:15.863Z"}, {"duration": 110, "start_time": "2025-05-02T03:49:16.052Z"}, {"duration": 1560, "start_time": "2025-05-02T03:49:16.164Z"}, {"duration": 9608, "start_time": "2025-05-02T03:49:17.726Z"}, {"duration": 263425, "start_time": "2025-05-02T03:49:27.340Z"}, {"duration": 4186, "start_time": "2025-05-02T03:53:50.769Z"}, {"duration": 171, "start_time": "2025-05-02T04:36:14.871Z"}, {"duration": 1105, "start_time": "2025-05-02T04:36:33.397Z"}, {"duration": 829, "start_time": "2025-05-02T04:36:34.504Z"}, {"duration": 353, "start_time": "2025-05-02T04:36:35.335Z"}, {"duration": 187, "start_time": "2025-05-02T04:36:35.689Z"}, {"duration": 108, "start_time": "2025-05-02T04:36:35.879Z"}, {"duration": 1535, "start_time": "2025-05-02T04:36:35.989Z"}, {"duration": 10620, "start_time": "2025-05-02T04:36:37.526Z"}, {"duration": 262258, "start_time": "2025-05-02T04:36:48.148Z"}, {"duration": 4238, "start_time": "2025-05-02T04:41:10.410Z"}, {"duration": 169, "start_time": "2025-05-05T01:03:01.669Z"}, {"duration": 2680, "start_time": "2025-05-05T01:03:10.555Z"}, {"duration": 846, "start_time": "2025-05-05T01:03:13.238Z"}, {"duration": 344, "start_time": "2025-05-05T01:03:14.085Z"}, {"duration": 180, "start_time": "2025-05-05T01:03:14.432Z"}, {"duration": 103, "start_time": "2025-05-05T01:03:14.614Z"}, {"duration": 1518, "start_time": "2025-05-05T01:03:14.719Z"}, {"duration": 8746, "start_time": "2025-05-05T01:03:16.239Z"}, {"duration": 245215, "start_time": "2025-05-05T01:03:24.987Z"}, {"duration": 4198, "start_time": "2025-05-05T01:07:30.204Z"}, {"duration": 809, "start_time": "2025-05-05T02:26:44.438Z"}, {"duration": 1151, "start_time": "2025-05-05T02:26:53.711Z"}, {"duration": 861, "start_time": "2025-05-05T02:26:54.864Z"}, {"duration": 358, "start_time": "2025-05-05T02:26:55.727Z"}, {"duration": 172, "start_time": "2025-05-05T02:26:56.087Z"}, {"duration": 111, "start_time": "2025-05-05T02:26:56.261Z"}, {"duration": 1513, "start_time": "2025-05-05T02:26:56.374Z"}, {"duration": 9681, "start_time": "2025-05-05T02:26:57.889Z"}, {"duration": 282480, "start_time": "2025-05-05T02:27:07.575Z"}, {"duration": 299422, "start_time": "2025-05-05T02:31:50.057Z"}, {"duration": 2757, "start_time": "2025-05-05T22:32:50.467Z"}, {"duration": 830, "start_time": "2025-05-05T22:32:53.226Z"}, {"duration": 351, "start_time": "2025-05-05T22:32:54.058Z"}, {"duration": 174, "start_time": "2025-05-05T22:32:54.411Z"}, {"duration": 103, "start_time": "2025-05-05T22:32:54.589Z"}, {"duration": 1447, "start_time": "2025-05-05T22:32:54.694Z"}, {"duration": 9370, "start_time": "2025-05-05T22:32:56.143Z"}, {"duration": 254687, "start_time": "2025-05-05T22:33:05.515Z"}, {"duration": 4401, "start_time": "2025-05-05T22:37:20.209Z"}, {"duration": 7273276, "start_time": "2025-05-05T22:37:24.614Z"}, {"duration": 2832, "start_time": "2025-05-09T03:33:16.819Z"}, {"duration": 844, "start_time": "2025-05-09T03:33:19.653Z"}, {"duration": 345, "start_time": "2025-05-09T03:33:20.498Z"}, {"duration": 168, "start_time": "2025-05-09T03:33:20.846Z"}, {"duration": 105, "start_time": "2025-05-09T03:33:21.024Z"}, {"duration": 7, "start_time": "2025-05-09T03:33:21.131Z"}, {"duration": 0, "start_time": "2025-05-09T03:33:21.140Z"}, {"duration": 0, "start_time": "2025-05-09T03:33:21.141Z"}, {"duration": 0, "start_time": "2025-05-09T03:33:21.142Z"}, {"duration": 0, "start_time": "2025-05-09T03:33:21.143Z"}, {"duration": 0, "start_time": "2025-05-09T03:33:21.144Z"}, {"duration": 5, "start_time": "2025-05-09T03:34:06.841Z"}, {"duration": 622, "start_time": "2025-05-09T03:34:47.054Z"}, {"duration": 227, "start_time": "2025-05-09T03:35:00.559Z"}, {"duration": 347, "start_time": "2025-05-09T03:39:37.494Z"}, {"duration": 281, "start_time": "2025-05-09T03:40:24.165Z"}, {"duration": 623, "start_time": "2025-05-09T03:41:49.148Z"}, {"duration": 301, "start_time": "2025-05-09T03:42:24.136Z"}, {"duration": 242, "start_time": "2025-05-09T03:43:38.203Z"}, {"duration": 71374, "start_time": "2025-05-09T03:46:47.071Z"}, {"duration": 223, "start_time": "2025-05-09T03:48:32.011Z"}, {"duration": 78496, "start_time": "2025-05-09T03:48:41.587Z"}, {"duration": 3316, "start_time": "2025-05-09T03:55:04.817Z"}, {"duration": 2674824, "start_time": "2025-05-09T03:59:20.123Z"}, {"duration": 94, "start_time": "2025-05-09T04:50:04.500Z"}, {"duration": 4, "start_time": "2025-05-09T04:51:14.002Z"}, {"duration": 6609811, "start_time": "2025-05-09T04:51:20.441Z"}, {"duration": 8, "start_time": "2025-05-09T11:44:16.511Z"}, {"duration": 8, "start_time": "2025-05-10T11:21:25.676Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}